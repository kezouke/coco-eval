{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9121c32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kezouke/Thesis/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import LlavaNextProcessor, LlavaNextForConditionalGeneration\n",
    "from huggingface_hub import login\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import re\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca8adb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to Hugging Face\n",
    "your_hf_token = \"\"\n",
    "login(token=your_hf_token)\n",
    "\n",
    "# Configuration\n",
    "MODEL_PATH = \"llava-hf/llama3-llava-next-8b-hf\"\n",
    "IMAGE_DIR = \"Thesis/coco2014/test2014\"\n",
    "OUTPUT_FILE = \"llama3_llava_next_8b_coco_results_test.json\"\n",
    "BATCH_SIZE = 8\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Generation parameters\n",
    "GENERATION_PARAMS = {\n",
    "    \"max_new_tokens\": 70,\n",
    "    \"do_sample\": False,\n",
    "    \"use_cache\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb46767c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free GPU memory: 23.30 GB\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Free GPU memory: {torch.cuda.mem_get_info()[0] / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e76cdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_processor(model_path, device):\n",
    "    \"\"\"Load LLaVA-NeXT model and processor.\"\"\"\n",
    "    print(f\"Loading model: {model_path}\")\n",
    "    \n",
    "    processor = LlavaNextProcessor.from_pretrained(model_path)\n",
    "    model = LlavaNextForConditionalGeneration.from_pretrained(\n",
    "        model_path,\n",
    "        torch_dtype=torch.float16,\n",
    "        low_cpu_mem_usage=True,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=False\n",
    "    ).eval()\n",
    "    \n",
    "    print(f\"✓ Model and processor loaded successfully on {next(model.parameters()).device}\")\n",
    "    return model, processor\n",
    "\n",
    "def extract_image_id(filename):\n",
    "    \"\"\"\n",
    "    Extract image ID from COCO test filename.\n",
    "    Example: 'COCO_test2014_000000123456.jpg' -> 123456\n",
    "    \"\"\"\n",
    "    match = re.search(r'(\\d{12})\\.(jpg|jpeg|png)$', filename, re.IGNORECASE)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        raise ValueError(f\"Could not extract image ID from filename: {filename}\")\n",
    "\n",
    "def clean_caption(caption_text):\n",
    "    \"\"\"\n",
    "    Clean the generated caption by removing conversation template artifacts.\n",
    "    \"\"\"\n",
    "    # Method 1: Split on assistant header (most reliable for LLaMA 3 format)\n",
    "    if \"<|start_header_id|>assistant<|end_header_id|>\" in caption_text:\n",
    "        parts = caption_text.split(\"<|start_header_id|>assistant<|end_header_id|>\")\n",
    "        if len(parts) > 1:\n",
    "            assistant_response = parts[-1]\n",
    "            # Remove any remaining special tokens and clean up\n",
    "            assistant_response = assistant_response.split(\"<|eot_id|>\")[0].strip()\n",
    "            return assistant_response\n",
    "    \n",
    "    # Method 2: Look for \"assistant\" keyword followed by the actual response\n",
    "    if \"assistant\" in caption_text.lower():\n",
    "        # Split on \"assistant\" and take the last part\n",
    "        parts = re.split(r'assistant\\s*', caption_text, flags=re.IGNORECASE)\n",
    "        if len(parts) > 1:\n",
    "            response = parts[-1].strip()\n",
    "            # Remove any remaining prompt artifacts\n",
    "            if response.startswith(\"Generate a detailed caption\"):\n",
    "                response = response.split(\"Generate a detailed caption\")[-1].strip()\n",
    "                if response.startswith(\"for this image in one sentence.\"):\n",
    "                    response = response[len(\"for this image in one sentence.\"):].strip()\n",
    "            return response\n",
    "    \n",
    "    # Method 3: Remove the user prompt if it appears at the beginning\n",
    "    prompt_text = \"Generate a detailed caption for this image in one sentence.\"\n",
    "    if caption_text.startswith(prompt_text):\n",
    "        caption_text = caption_text[len(prompt_text):].strip()\n",
    "    \n",
    "    # Final cleanup: remove any remaining special tokens or artifacts\n",
    "    caption_text = caption_text.replace(\"<|start_header_id|>\", \"\")\n",
    "    caption_text = caption_text.replace(\"<|end_header_id|>\", \"\")\n",
    "    caption_text = caption_text.replace(\"<|eot_id|>\", \"\")\n",
    "    caption_text = caption_text.replace(\"user\", \"\").replace(\"assistant\", \"\")\n",
    "    caption_text = re.sub(r'\\s+', ' ', caption_text).strip()\n",
    "    \n",
    "    return caption_text\n",
    "\n",
    "def generate_caption_single_optimized(image_path, model, processor, device):\n",
    "    \"\"\"Generate caption for a single image using LLaVA-NeXT with memory efficiency.\"\"\"\n",
    "    try:\n",
    "        # Open image directly without verification to save time\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        \n",
    "        conversation = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": \"Generate a detailed caption for this image in one sentence.\"},\n",
    "                    {\"type\": \"image\"},\n",
    "                ],\n",
    "            },\n",
    "        ]\n",
    "        \n",
    "        # Apply chat template\n",
    "        prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "        \n",
    "        # Process single image\n",
    "        inputs = processor(\n",
    "            images=image,\n",
    "            text=prompt,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=False,\n",
    "            truncation=False\n",
    "        ).to(device)\n",
    "        \n",
    "        # Convert pixel values to float16 for memory efficiency\n",
    "        if \"pixel_values\" in inputs:\n",
    "            inputs[\"pixel_values\"] = inputs[\"pixel_values\"].to(torch.float16)\n",
    "        \n",
    "        # Generate with optimized settings\n",
    "        with torch.no_grad():\n",
    "            output = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=GENERATION_PARAMS[\"max_new_tokens\"],\n",
    "                do_sample=GENERATION_PARAMS[\"do_sample\"],\n",
    "                use_cache=GENERATION_PARAMS[\"use_cache\"],\n",
    "                pad_token_id=processor.tokenizer.pad_token_id,\n",
    "                eos_token_id=processor.tokenizer.eos_token_id\n",
    "            )\n",
    "        \n",
    "        # Decode with special tokens to properly parse the structure\n",
    "        full_output = processor.decode(output[0], skip_special_tokens=False)\n",
    "        \n",
    "        # Clean and extract the actual caption\n",
    "        clean_caption_text = clean_caption(full_output)\n",
    "        \n",
    "        # Final validation\n",
    "        if not clean_caption_text or len(clean_caption_text) < 5:\n",
    "            # Fallback: try decoding without special tokens\n",
    "            fallback_caption = processor.decode(output[0], skip_special_tokens=True).strip()\n",
    "            clean_caption_text = clean_caption(fallback_caption)\n",
    "        \n",
    "        return clean_caption_text if clean_caption_text else \"No caption generated\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "        return \"Error generating caption\"\n",
    "    finally:\n",
    "        # Clear image from memory\n",
    "        if 'image' in locals():\n",
    "            del image\n",
    "\n",
    "def process_batch_efficient(image_paths, model, processor, device):\n",
    "    \"\"\"\n",
    "    Process a batch of images efficiently using single-image processing.\n",
    "    \"\"\"\n",
    "    captions = []\n",
    "    for img_path in image_paths:\n",
    "        caption = generate_caption_single_optimized(img_path, model, processor, device)\n",
    "        captions.append(caption)\n",
    "        \n",
    "        # Clear CUDA cache after each image to prevent memory buildup\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return captions\n",
    "\n",
    "def get_image_files(image_dir):\n",
    "    \"\"\"Get sorted list of image files with robust error handling.\"\"\"\n",
    "    try:\n",
    "        all_files = os.listdir(image_dir)\n",
    "        image_files = [f for f in all_files if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        print(f\"\\nFound {len(image_files)} images in {image_dir}\")\n",
    "        \n",
    "        # Sort for reproducibility\n",
    "        image_files.sort()\n",
    "        \n",
    "        return image_files\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading image directory: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0da03114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: llava-hf/llama3-llava-next-8b-hf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [02:11<00:00, 32.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model and processor loaded successfully on cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Load model and processor\n",
    "model, processor = load_model_and_processor(MODEL_PATH, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80881703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 40775 images in /home/kezouke/Thesis/coco2014/test2014\n",
      "\n",
      "Testing on first batch...\n",
      "Sample files to process:\n",
      "  - /home/kezouke/Thesis/coco2014/test2014/COCO_test2014_000000000001.jpg\n",
      "  - /home/kezouke/Thesis/coco2014/test2014/COCO_test2014_000000000014.jpg\n",
      "  - /home/kezouke/Thesis/coco2014/test2014/COCO_test2014_000000000016.jpg\n",
      "\n",
      "CLEAN Sample captions from first batch:\n",
      "  1. Image ID: 1\n",
      "     File: COCO_test2014_000000000001.jpg\n",
      "     Caption: A taxi cab parked next to a black iron fence.\n",
      "  2. Image ID: 14\n",
      "     File: COCO_test2014_000000000014.jpg\n",
      "     Caption: A man riding a skateboard down a street next to a man on a motorcycle.\n",
      "  3. Image ID: 16\n",
      "     File: COCO_test2014_000000000016.jpg\n",
      "     Caption: A baseball player swinging a bat at a ball.\n"
     ]
    }
   ],
   "source": [
    "# Get image files\n",
    "image_files = get_image_files(IMAGE_DIR)\n",
    "if not image_files:\n",
    "    raise ValueError(\"No image files found in the test directory\")\n",
    "\n",
    "# Test on first few images\n",
    "print(\"\\nTesting on first batch...\")\n",
    "test_batch_size = min(3, len(image_files))\n",
    "test_paths = [os.path.join(IMAGE_DIR, image_files[i]) for i in range(test_batch_size)]\n",
    "\n",
    "print(\"Sample files to process:\")\n",
    "for path in test_paths:\n",
    "    print(f\"  - {path}\")\n",
    "\n",
    "try:\n",
    "    test_captions = process_batch_efficient(test_paths, model, processor, DEVICE)\n",
    "    print(\"\\nCLEAN Sample captions from first batch:\")\n",
    "    for i, (filename, caption) in enumerate(zip(image_files[:test_batch_size], test_captions)):\n",
    "        img_id = extract_image_id(filename)\n",
    "        print(f\"  {i+1}. Image ID: {img_id}\")\n",
    "        print(f\"     File: {filename}\")\n",
    "        print(f\"     Caption: {caption}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during test batch processing: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffb3f62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   0%|          | 6/5097 [00:45<10:32:59,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_5.json (48 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   0%|          | 11/5097 [01:22<10:33:32,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_10.json (88 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   0%|          | 16/5097 [01:58<10:23:19,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_15.json (128 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   0%|          | 21/5097 [02:35<10:23:17,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_20.json (168 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   1%|          | 26/5097 [03:12<10:20:51,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_25.json (208 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   1%|          | 31/5097 [03:49<10:27:57,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_30.json (248 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   1%|          | 36/5097 [04:26<10:11:29,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_35.json (288 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   1%|          | 41/5097 [05:03<10:22:26,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_40.json (328 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   1%|          | 46/5097 [05:39<10:15:33,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_45.json (368 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   1%|          | 51/5097 [06:17<10:34:26,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_50.json (408 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   1%|          | 56/5097 [06:55<10:26:58,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_55.json (448 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   1%|          | 61/5097 [07:31<10:20:57,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_60.json (488 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   1%|▏         | 66/5097 [08:08<10:17:08,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_65.json (528 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   1%|▏         | 71/5097 [08:45<10:31:34,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_70.json (568 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   1%|▏         | 76/5097 [09:22<10:22:35,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_75.json (608 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   2%|▏         | 81/5097 [09:59<10:16:29,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_80.json (648 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   2%|▏         | 86/5097 [10:35<9:59:29,  7.18s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_85.json (688 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   2%|▏         | 91/5097 [11:12<10:09:51,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_90.json (728 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   2%|▏         | 96/5097 [11:48<10:14:03,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_95.json (768 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   2%|▏         | 101/5097 [12:25<10:10:16,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_100.json (808 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   2%|▏         | 106/5097 [13:03<10:32:02,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_105.json (848 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   2%|▏         | 111/5097 [13:40<10:15:07,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_110.json (888 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   2%|▏         | 116/5097 [14:18<10:21:29,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_115.json (928 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   2%|▏         | 121/5097 [14:55<10:24:53,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_120.json (968 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   2%|▏         | 126/5097 [15:34<10:34:35,  7.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_125.json (1008 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   3%|▎         | 131/5097 [16:11<10:22:43,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_130.json (1048 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   3%|▎         | 136/5097 [16:49<10:23:10,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_135.json (1088 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   3%|▎         | 141/5097 [17:27<10:39:50,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_140.json (1128 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   3%|▎         | 146/5097 [18:05<10:30:40,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_145.json (1168 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   3%|▎         | 151/5097 [18:42<10:10:45,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_150.json (1208 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   3%|▎         | 156/5097 [19:20<10:23:18,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_155.json (1248 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   3%|▎         | 161/5097 [19:57<10:17:50,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_160.json (1288 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   3%|▎         | 166/5097 [20:34<10:05:13,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_165.json (1328 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   3%|▎         | 171/5097 [21:12<10:07:32,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_170.json (1368 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   3%|▎         | 176/5097 [21:49<10:19:02,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_175.json (1408 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   4%|▎         | 181/5097 [22:27<10:20:06,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_180.json (1448 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   4%|▎         | 186/5097 [23:04<10:18:20,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_185.json (1488 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   4%|▎         | 191/5097 [23:42<10:13:13,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_190.json (1528 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   4%|▍         | 196/5097 [24:19<10:17:11,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_195.json (1568 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   4%|▍         | 201/5097 [24:56<10:01:10,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_200.json (1608 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   4%|▍         | 206/5097 [25:34<10:11:35,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_205.json (1648 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   4%|▍         | 211/5097 [26:11<10:05:40,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_210.json (1688 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   4%|▍         | 216/5097 [26:49<10:10:24,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_215.json (1728 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   4%|▍         | 221/5097 [27:26<10:18:57,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_220.json (1768 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   4%|▍         | 226/5097 [28:03<10:04:58,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_225.json (1808 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   5%|▍         | 231/5097 [28:40<10:03:56,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_230.json (1848 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   5%|▍         | 236/5097 [29:18<10:01:49,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_235.json (1888 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   5%|▍         | 241/5097 [29:56<10:08:39,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_240.json (1928 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   5%|▍         | 246/5097 [30:32<9:56:20,  7.38s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_245.json (1968 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   5%|▍         | 251/5097 [31:09<9:50:43,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_250.json (2008 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   5%|▌         | 256/5097 [31:46<9:59:54,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_255.json (2048 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   5%|▌         | 261/5097 [32:24<10:06:58,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_260.json (2088 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   5%|▌         | 266/5097 [33:01<10:03:19,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_265.json (2128 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   5%|▌         | 271/5097 [33:38<9:45:41,  7.28s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_270.json (2168 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   5%|▌         | 276/5097 [34:16<10:02:05,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_275.json (2208 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   6%|▌         | 281/5097 [34:54<10:10:31,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_280.json (2248 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   6%|▌         | 286/5097 [35:31<9:45:41,  7.30s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_285.json (2288 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   6%|▌         | 291/5097 [36:07<9:42:38,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_290.json (2328 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   6%|▌         | 296/5097 [36:44<9:50:46,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_295.json (2368 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   6%|▌         | 301/5097 [37:21<9:40:56,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_300.json (2408 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   6%|▌         | 306/5097 [37:57<9:40:20,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_305.json (2448 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   6%|▌         | 311/5097 [38:34<9:31:19,  7.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_310.json (2488 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   6%|▌         | 316/5097 [39:10<9:36:27,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_315.json (2528 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   6%|▋         | 321/5097 [39:47<9:44:03,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_320.json (2568 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   6%|▋         | 326/5097 [40:24<9:47:21,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_325.json (2608 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   6%|▋         | 331/5097 [41:02<9:46:12,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_330.json (2648 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   7%|▋         | 336/5097 [41:39<9:51:23,  7.45s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_335.json (2688 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   7%|▋         | 341/5097 [42:16<9:54:08,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_340.json (2728 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   7%|▋         | 346/5097 [42:53<9:47:03,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_345.json (2768 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   7%|▋         | 351/5097 [43:29<9:35:33,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_350.json (2808 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   7%|▋         | 356/5097 [44:06<9:39:42,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_355.json (2848 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   7%|▋         | 361/5097 [44:43<9:47:36,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_360.json (2888 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   7%|▋         | 366/5097 [45:21<9:51:07,  7.50s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_365.json (2928 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   7%|▋         | 371/5097 [45:59<9:51:37,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_370.json (2968 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   7%|▋         | 376/5097 [46:35<9:42:23,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_375.json (3008 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   7%|▋         | 381/5097 [47:13<9:42:07,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_380.json (3048 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   8%|▊         | 386/5097 [47:50<9:43:23,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_385.json (3088 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   8%|▊         | 391/5097 [48:28<9:48:40,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_390.json (3128 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   8%|▊         | 396/5097 [49:06<9:56:48,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_395.json (3168 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   8%|▊         | 401/5097 [49:43<9:48:35,  7.52s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_400.json (3208 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   8%|▊         | 406/5097 [50:21<9:48:32,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_405.json (3248 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   8%|▊         | 411/5097 [50:59<9:45:28,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_410.json (3288 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   8%|▊         | 416/5097 [51:36<9:48:05,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_415.json (3328 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   8%|▊         | 421/5097 [52:15<9:48:53,  7.56s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_420.json (3368 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   8%|▊         | 426/5097 [52:52<9:42:11,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_425.json (3408 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   8%|▊         | 431/5097 [53:30<9:44:31,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_430.json (3448 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   9%|▊         | 436/5097 [54:07<9:41:42,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_435.json (3488 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   9%|▊         | 441/5097 [54:44<9:20:31,  7.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_440.json (3528 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   9%|▉         | 446/5097 [55:22<9:45:58,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_445.json (3568 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   9%|▉         | 451/5097 [55:59<9:45:33,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_450.json (3608 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   9%|▉         | 456/5097 [56:37<9:41:36,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_455.json (3648 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   9%|▉         | 461/5097 [57:15<9:27:19,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_460.json (3688 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   9%|▉         | 466/5097 [57:53<9:42:11,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_465.json (3728 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   9%|▉         | 471/5097 [58:30<9:38:34,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_470.json (3768 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   9%|▉         | 476/5097 [59:08<9:39:29,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_475.json (3808 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   9%|▉         | 481/5097 [59:46<9:47:00,  7.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_480.json (3848 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  10%|▉         | 486/5097 [1:00:22<9:24:25,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_485.json (3888 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  10%|▉         | 491/5097 [1:01:00<9:29:43,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_490.json (3928 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  10%|▉         | 496/5097 [1:01:38<9:47:44,  7.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_495.json (3968 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  10%|▉         | 501/5097 [1:02:15<9:29:15,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_500.json (4008 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  10%|▉         | 506/5097 [1:02:53<9:35:36,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_505.json (4048 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  10%|█         | 511/5097 [1:03:30<9:38:36,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_510.json (4088 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  10%|█         | 516/5097 [1:04:08<9:42:11,  7.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_515.json (4128 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  10%|█         | 521/5097 [1:04:46<9:45:07,  7.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_520.json (4168 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  10%|█         | 526/5097 [1:05:24<9:40:34,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_525.json (4208 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  10%|█         | 531/5097 [1:06:02<9:38:46,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_530.json (4248 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  11%|█         | 536/5097 [1:06:39<9:24:13,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_535.json (4288 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  11%|█         | 541/5097 [1:07:16<9:28:20,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_540.json (4328 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  11%|█         | 546/5097 [1:07:53<9:19:28,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_545.json (4368 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  11%|█         | 551/5097 [1:08:30<9:28:35,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_550.json (4408 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  11%|█         | 556/5097 [1:09:07<9:19:42,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_555.json (4448 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  11%|█         | 561/5097 [1:09:45<9:22:10,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_560.json (4488 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  11%|█         | 566/5097 [1:10:21<9:11:26,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_565.json (4528 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  11%|█         | 571/5097 [1:10:59<9:25:01,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_570.json (4568 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  11%|█▏        | 576/5097 [1:11:37<9:29:09,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_575.json (4608 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  11%|█▏        | 581/5097 [1:12:15<9:36:45,  7.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_580.json (4648 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  11%|█▏        | 586/5097 [1:12:52<9:16:23,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_585.json (4688 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  12%|█▏        | 591/5097 [1:13:29<9:11:09,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_590.json (4728 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  12%|█▏        | 596/5097 [1:14:07<9:27:26,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_595.json (4768 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  12%|█▏        | 601/5097 [1:14:44<9:24:58,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_600.json (4808 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  12%|█▏        | 606/5097 [1:15:21<9:17:43,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_605.json (4848 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  12%|█▏        | 611/5097 [1:15:59<9:20:04,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_610.json (4888 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  12%|█▏        | 616/5097 [1:16:37<9:27:10,  7.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_615.json (4928 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  12%|█▏        | 621/5097 [1:17:15<9:28:40,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_620.json (4968 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  12%|█▏        | 626/5097 [1:17:52<9:17:06,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_625.json (5008 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  12%|█▏        | 631/5097 [1:18:29<9:08:59,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_630.json (5048 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  12%|█▏        | 636/5097 [1:19:08<9:19:18,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_635.json (5088 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  13%|█▎        | 641/5097 [1:19:46<9:20:00,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_640.json (5128 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  13%|█▎        | 646/5097 [1:20:23<9:17:36,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_645.json (5168 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  13%|█▎        | 651/5097 [1:21:01<9:18:58,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_650.json (5208 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  13%|█▎        | 656/5097 [1:21:39<9:20:56,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_655.json (5248 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  13%|█▎        | 661/5097 [1:22:17<9:16:13,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_660.json (5288 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  13%|█▎        | 666/5097 [1:22:55<9:21:15,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_665.json (5328 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  13%|█▎        | 671/5097 [1:23:33<9:19:04,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_670.json (5368 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  13%|█▎        | 676/5097 [1:24:11<9:16:52,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_675.json (5408 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  13%|█▎        | 681/5097 [1:24:48<9:11:39,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_680.json (5448 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  13%|█▎        | 686/5097 [1:25:26<9:00:17,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_685.json (5488 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  14%|█▎        | 691/5097 [1:26:04<9:14:59,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_690.json (5528 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  14%|█▎        | 696/5097 [1:26:41<9:16:19,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_695.json (5568 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  14%|█▍        | 701/5097 [1:27:18<9:02:32,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_700.json (5608 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  14%|█▍        | 706/5097 [1:27:56<9:17:45,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_705.json (5648 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  14%|█▍        | 711/5097 [1:28:34<9:09:46,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_710.json (5688 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  14%|█▍        | 716/5097 [1:29:11<9:08:23,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_715.json (5728 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  14%|█▍        | 721/5097 [1:29:49<9:08:23,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_720.json (5768 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  14%|█▍        | 726/5097 [1:30:26<8:58:27,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_725.json (5808 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  14%|█▍        | 731/5097 [1:31:03<8:51:14,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_730.json (5848 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  14%|█▍        | 736/5097 [1:31:40<9:00:31,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_735.json (5888 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  15%|█▍        | 741/5097 [1:32:19<9:18:52,  7.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_740.json (5928 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  15%|█▍        | 746/5097 [1:32:57<9:10:11,  7.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_745.json (5968 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  15%|█▍        | 751/5097 [1:33:35<9:11:50,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_750.json (6008 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  15%|█▍        | 756/5097 [1:34:13<9:09:49,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_755.json (6048 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  15%|█▍        | 761/5097 [1:34:50<8:59:04,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_760.json (6088 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  15%|█▌        | 766/5097 [1:35:28<9:05:18,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_765.json (6128 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  15%|█▌        | 771/5097 [1:36:07<9:09:10,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_770.json (6168 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  15%|█▌        | 776/5097 [1:36:44<8:59:36,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_775.json (6208 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  15%|█▌        | 781/5097 [1:37:21<8:56:40,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_780.json (6248 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  15%|█▌        | 786/5097 [1:37:59<8:58:41,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_785.json (6288 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  16%|█▌        | 791/5097 [1:38:37<9:00:30,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_790.json (6328 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  16%|█▌        | 796/5097 [1:39:14<8:57:44,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_795.json (6368 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  16%|█▌        | 801/5097 [1:39:52<8:56:37,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_800.json (6408 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  16%|█▌        | 806/5097 [1:40:29<8:59:24,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_805.json (6448 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  16%|█▌        | 811/5097 [1:41:07<9:00:48,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_810.json (6488 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  16%|█▌        | 816/5097 [1:41:45<9:08:42,  7.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_815.json (6528 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  16%|█▌        | 821/5097 [1:42:22<8:48:09,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_820.json (6568 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  16%|█▌        | 826/5097 [1:43:00<8:56:55,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_825.json (6608 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  16%|█▋        | 831/5097 [1:43:37<8:43:16,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_830.json (6648 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  16%|█▋        | 836/5097 [1:44:15<8:46:40,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_835.json (6688 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  16%|█▋        | 841/5097 [1:44:53<8:52:18,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_840.json (6728 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  17%|█▋        | 846/5097 [1:45:31<8:57:25,  7.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_845.json (6768 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  17%|█▋        | 851/5097 [1:46:09<9:00:25,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_850.json (6808 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  17%|█▋        | 856/5097 [1:46:48<9:03:01,  7.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_855.json (6848 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  17%|█▋        | 861/5097 [1:47:25<8:51:45,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_860.json (6888 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  17%|█▋        | 866/5097 [1:48:03<9:02:11,  7.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_865.json (6928 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  17%|█▋        | 871/5097 [1:48:42<9:05:00,  7.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_870.json (6968 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  17%|█▋        | 876/5097 [1:49:20<8:59:28,  7.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_875.json (7008 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  17%|█▋        | 881/5097 [1:49:58<8:46:18,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_880.json (7048 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  17%|█▋        | 886/5097 [1:50:35<8:42:13,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_885.json (7088 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  17%|█▋        | 891/5097 [1:51:12<8:44:15,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_890.json (7128 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  18%|█▊        | 896/5097 [1:51:50<8:52:45,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_895.json (7168 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  18%|█▊        | 901/5097 [1:52:29<8:52:35,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_900.json (7208 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  18%|█▊        | 906/5097 [1:53:06<8:49:36,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_905.json (7248 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  18%|█▊        | 911/5097 [1:53:43<8:40:28,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_910.json (7288 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  18%|█▊        | 916/5097 [1:54:20<8:33:41,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_915.json (7328 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  18%|█▊        | 921/5097 [1:54:58<8:41:43,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_920.json (7368 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  18%|█▊        | 926/5097 [1:55:35<8:29:53,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_925.json (7408 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  18%|█▊        | 931/5097 [1:56:13<8:44:53,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_930.json (7448 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  18%|█▊        | 936/5097 [1:56:50<8:44:40,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_935.json (7488 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  18%|█▊        | 941/5097 [1:57:28<8:49:08,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_940.json (7528 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  19%|█▊        | 946/5097 [1:58:07<8:54:08,  7.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_945.json (7568 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  19%|█▊        | 951/5097 [1:58:45<8:45:39,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_950.json (7608 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  19%|█▉        | 956/5097 [1:59:23<8:47:16,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_955.json (7648 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  19%|█▉        | 961/5097 [2:00:00<8:34:43,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_960.json (7688 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  19%|█▉        | 966/5097 [2:00:37<8:26:45,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_965.json (7728 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  19%|█▉        | 971/5097 [2:01:15<8:30:58,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_970.json (7768 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  19%|█▉        | 976/5097 [2:01:52<8:41:30,  7.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_975.json (7808 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  19%|█▉        | 981/5097 [2:02:30<8:35:38,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_980.json (7848 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  19%|█▉        | 986/5097 [2:03:08<8:37:35,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_985.json (7888 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  19%|█▉        | 991/5097 [2:03:46<8:34:00,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_990.json (7928 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  20%|█▉        | 996/5097 [2:04:23<8:33:54,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_995.json (7968 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  20%|█▉        | 1001/5097 [2:05:01<8:44:53,  7.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1000.json (8008 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  20%|█▉        | 1006/5097 [2:05:39<8:34:50,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1005.json (8048 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  20%|█▉        | 1011/5097 [2:06:16<8:25:44,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1010.json (8088 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  20%|█▉        | 1016/5097 [2:06:54<8:32:35,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1015.json (8128 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  20%|██        | 1021/5097 [2:07:31<8:27:42,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1020.json (8168 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  20%|██        | 1026/5097 [2:08:10<8:40:42,  7.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1025.json (8208 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  20%|██        | 1031/5097 [2:08:47<8:31:56,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1030.json (8248 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  20%|██        | 1036/5097 [2:09:26<8:42:31,  7.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1035.json (8288 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  20%|██        | 1041/5097 [2:10:04<8:34:39,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1040.json (8328 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  21%|██        | 1046/5097 [2:10:42<8:27:54,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1045.json (8368 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  21%|██        | 1051/5097 [2:11:20<8:35:02,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1050.json (8408 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  21%|██        | 1056/5097 [2:11:57<8:24:36,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1055.json (8448 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  21%|██        | 1061/5097 [2:12:35<8:24:49,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1060.json (8488 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  21%|██        | 1066/5097 [2:13:12<8:29:10,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1065.json (8528 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  21%|██        | 1071/5097 [2:13:50<8:20:37,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1070.json (8568 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  21%|██        | 1076/5097 [2:14:28<8:28:30,  7.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1075.json (8608 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  21%|██        | 1081/5097 [2:15:04<8:12:33,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1080.json (8648 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  21%|██▏       | 1086/5097 [2:15:43<8:38:48,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1085.json (8688 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  21%|██▏       | 1091/5097 [2:16:20<8:20:59,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1090.json (8728 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  22%|██▏       | 1096/5097 [2:16:58<8:23:15,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1095.json (8768 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  22%|██▏       | 1101/5097 [2:17:36<8:23:00,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1100.json (8808 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  22%|██▏       | 1106/5097 [2:18:14<8:28:47,  7.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1105.json (8848 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  22%|██▏       | 1111/5097 [2:18:52<8:24:55,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1110.json (8888 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  22%|██▏       | 1116/5097 [2:19:31<8:31:17,  7.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1115.json (8928 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  22%|██▏       | 1121/5097 [2:20:10<8:37:21,  7.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1120.json (8968 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  22%|██▏       | 1126/5097 [2:20:49<8:36:21,  7.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1125.json (9008 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  22%|██▏       | 1131/5097 [2:21:25<8:06:39,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1130.json (9048 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  22%|██▏       | 1136/5097 [2:22:03<8:13:03,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1135.json (9088 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  22%|██▏       | 1141/5097 [2:22:41<8:18:50,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1140.json (9128 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  22%|██▏       | 1146/5097 [2:23:19<8:23:25,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1145.json (9168 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  23%|██▎       | 1151/5097 [2:23:55<7:54:42,  7.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1150.json (9208 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  23%|██▎       | 1156/5097 [2:24:33<8:13:12,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1155.json (9248 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  23%|██▎       | 1161/5097 [2:25:11<8:20:26,  7.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1160.json (9288 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  23%|██▎       | 1166/5097 [2:25:48<8:00:26,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1165.json (9328 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  23%|██▎       | 1171/5097 [2:26:25<8:04:43,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1170.json (9368 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  23%|██▎       | 1176/5097 [2:27:03<8:10:10,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1175.json (9408 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  23%|██▎       | 1181/5097 [2:27:41<8:15:48,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1180.json (9448 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  23%|██▎       | 1186/5097 [2:28:19<8:15:27,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1185.json (9488 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  23%|██▎       | 1191/5097 [2:28:56<8:04:25,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1190.json (9528 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  23%|██▎       | 1196/5097 [2:29:34<8:00:11,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1195.json (9568 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  24%|██▎       | 1201/5097 [2:30:11<8:07:31,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1200.json (9608 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  24%|██▎       | 1206/5097 [2:30:48<7:58:26,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1205.json (9648 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  24%|██▍       | 1211/5097 [2:31:26<8:15:57,  7.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1210.json (9688 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  24%|██▍       | 1216/5097 [2:32:04<8:10:06,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1215.json (9728 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  24%|██▍       | 1221/5097 [2:32:41<8:06:03,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1220.json (9768 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  24%|██▍       | 1226/5097 [2:33:18<7:58:19,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1225.json (9808 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  24%|██▍       | 1231/5097 [2:33:56<8:02:14,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1230.json (9848 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  24%|██▍       | 1236/5097 [2:34:33<8:02:39,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1235.json (9888 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  24%|██▍       | 1241/5097 [2:35:11<8:02:42,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1240.json (9928 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  24%|██▍       | 1246/5097 [2:35:48<7:59:01,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1245.json (9968 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  25%|██▍       | 1251/5097 [2:36:26<8:00:36,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1250.json (10008 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  25%|██▍       | 1256/5097 [2:37:04<8:04:06,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1255.json (10048 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  25%|██▍       | 1261/5097 [2:37:41<7:58:05,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1260.json (10088 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  25%|██▍       | 1266/5097 [2:38:19<7:57:06,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1265.json (10128 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  25%|██▍       | 1271/5097 [2:38:56<7:52:25,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1270.json (10168 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  25%|██▌       | 1276/5097 [2:39:33<7:57:48,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1275.json (10208 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  25%|██▌       | 1281/5097 [2:40:11<7:59:11,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1280.json (10248 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  25%|██▌       | 1286/5097 [2:40:49<8:05:04,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1285.json (10288 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  25%|██▌       | 1291/5097 [2:41:28<8:07:21,  7.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1290.json (10328 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  25%|██▌       | 1296/5097 [2:42:06<8:07:19,  7.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1295.json (10368 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  26%|██▌       | 1301/5097 [2:42:43<7:42:59,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1300.json (10408 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  26%|██▌       | 1306/5097 [2:43:20<7:47:20,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1305.json (10448 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  26%|██▌       | 1311/5097 [2:43:58<7:56:01,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1310.json (10488 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  26%|██▌       | 1316/5097 [2:44:35<7:55:55,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1315.json (10528 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  26%|██▌       | 1321/5097 [2:45:13<7:54:11,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1320.json (10568 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  26%|██▌       | 1326/5097 [2:45:51<7:51:34,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1325.json (10608 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  26%|██▌       | 1331/5097 [2:46:28<7:56:14,  7.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1330.json (10648 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  26%|██▌       | 1336/5097 [2:47:07<7:55:05,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1335.json (10688 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  26%|██▋       | 1341/5097 [2:47:45<7:55:24,  7.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1340.json (10728 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  26%|██▋       | 1346/5097 [2:48:22<7:46:52,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1345.json (10768 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  27%|██▋       | 1351/5097 [2:49:00<7:54:28,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1350.json (10808 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  27%|██▋       | 1356/5097 [2:49:38<7:45:04,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1355.json (10848 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  27%|██▋       | 1361/5097 [2:50:16<7:51:18,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1360.json (10888 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  27%|██▋       | 1366/5097 [2:50:54<8:00:44,  7.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1365.json (10928 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  27%|██▋       | 1371/5097 [2:51:32<7:51:28,  7.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1370.json (10968 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  27%|██▋       | 1376/5097 [2:52:10<7:48:32,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1375.json (11008 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  27%|██▋       | 1381/5097 [2:52:48<7:49:15,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1380.json (11048 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  27%|██▋       | 1386/5097 [2:53:25<7:39:00,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1385.json (11088 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  27%|██▋       | 1391/5097 [2:54:02<7:39:12,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1390.json (11128 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  27%|██▋       | 1396/5097 [2:54:40<7:45:18,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1395.json (11168 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  27%|██▋       | 1401/5097 [2:55:17<7:42:40,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1400.json (11208 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  28%|██▊       | 1406/5097 [2:55:54<7:40:06,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1405.json (11248 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  28%|██▊       | 1411/5097 [2:56:31<7:35:17,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1410.json (11288 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  28%|██▊       | 1416/5097 [2:57:09<7:34:51,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1415.json (11328 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  28%|██▊       | 1421/5097 [2:57:47<7:42:43,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1420.json (11368 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  28%|██▊       | 1426/5097 [2:58:24<7:39:50,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1425.json (11408 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  28%|██▊       | 1431/5097 [2:59:02<7:38:11,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1430.json (11448 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  28%|██▊       | 1436/5097 [2:59:39<7:36:46,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1435.json (11488 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  28%|██▊       | 1441/5097 [3:00:15<7:17:06,  7.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1440.json (11528 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  28%|██▊       | 1446/5097 [3:00:52<7:24:25,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1445.json (11568 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  28%|██▊       | 1451/5097 [3:01:28<7:26:34,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1450.json (11608 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  29%|██▊       | 1456/5097 [3:02:05<7:20:02,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1455.json (11648 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  29%|██▊       | 1461/5097 [3:02:41<7:12:03,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1460.json (11688 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  29%|██▉       | 1466/5097 [3:03:18<7:22:38,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1465.json (11728 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  29%|██▉       | 1471/5097 [3:03:54<7:28:55,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1470.json (11768 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  29%|██▉       | 1476/5097 [3:04:31<7:26:55,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1475.json (11808 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  29%|██▉       | 1481/5097 [3:05:08<7:27:58,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1480.json (11848 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  29%|██▉       | 1486/5097 [3:05:46<7:25:40,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1485.json (11888 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  29%|██▉       | 1491/5097 [3:06:23<7:22:34,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1490.json (11928 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  29%|██▉       | 1496/5097 [3:07:00<7:27:06,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1495.json (11968 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  29%|██▉       | 1501/5097 [3:07:38<7:39:21,  7.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1500.json (12008 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  30%|██▉       | 1506/5097 [3:08:16<7:32:48,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1505.json (12048 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  30%|██▉       | 1511/5097 [3:08:53<7:28:47,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1510.json (12088 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  30%|██▉       | 1516/5097 [3:09:30<7:20:20,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1515.json (12128 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  30%|██▉       | 1521/5097 [3:10:08<7:28:32,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1520.json (12168 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  30%|██▉       | 1526/5097 [3:10:46<7:24:29,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1525.json (12208 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  30%|███       | 1531/5097 [3:11:23<7:19:40,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1530.json (12248 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  30%|███       | 1536/5097 [3:12:00<7:25:15,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1535.json (12288 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  30%|███       | 1541/5097 [3:12:36<7:10:54,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1540.json (12328 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  30%|███       | 1546/5097 [3:13:14<7:23:40,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1545.json (12368 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  30%|███       | 1551/5097 [3:13:50<7:13:56,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1550.json (12408 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  31%|███       | 1556/5097 [3:14:27<7:19:24,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1555.json (12448 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  31%|███       | 1561/5097 [3:15:04<7:14:00,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1560.json (12488 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  31%|███       | 1566/5097 [3:15:42<7:16:38,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1565.json (12528 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  31%|███       | 1571/5097 [3:16:20<7:29:22,  7.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1570.json (12568 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  31%|███       | 1576/5097 [3:16:56<7:18:07,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1575.json (12608 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  31%|███       | 1581/5097 [3:17:33<7:16:07,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1580.json (12648 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  31%|███       | 1586/5097 [3:18:11<7:13:38,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1585.json (12688 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  31%|███       | 1591/5097 [3:18:48<7:15:07,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1590.json (12728 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  31%|███▏      | 1596/5097 [3:19:25<7:12:00,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1595.json (12768 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  31%|███▏      | 1601/5097 [3:20:02<7:14:38,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1600.json (12808 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  32%|███▏      | 1606/5097 [3:20:39<7:14:46,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1605.json (12848 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  32%|███▏      | 1611/5097 [3:21:16<7:04:13,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1610.json (12888 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  32%|███▏      | 1616/5097 [3:21:53<7:03:16,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1615.json (12928 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  32%|███▏      | 1621/5097 [3:22:29<7:03:04,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1620.json (12968 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  32%|███▏      | 1626/5097 [3:23:07<7:19:00,  7.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1625.json (13008 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  32%|███▏      | 1631/5097 [3:23:44<7:04:52,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1630.json (13048 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  32%|███▏      | 1636/5097 [3:24:21<7:06:57,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1635.json (13088 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  32%|███▏      | 1641/5097 [3:24:58<7:10:02,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1640.json (13128 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  32%|███▏      | 1646/5097 [3:25:36<7:10:04,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1645.json (13168 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  32%|███▏      | 1651/5097 [3:26:13<7:05:13,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1650.json (13208 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  32%|███▏      | 1656/5097 [3:26:50<7:05:14,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1655.json (13248 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  33%|███▎      | 1661/5097 [3:27:26<6:53:41,  7.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1660.json (13288 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  33%|███▎      | 1666/5097 [3:28:03<6:56:55,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1665.json (13328 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  33%|███▎      | 1671/5097 [3:28:42<7:10:25,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1670.json (13368 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  33%|███▎      | 1676/5097 [3:29:18<7:00:36,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1675.json (13408 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  33%|███▎      | 1681/5097 [3:29:55<6:57:53,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1680.json (13448 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  33%|███▎      | 1686/5097 [3:30:31<6:51:20,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1685.json (13488 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  33%|███▎      | 1691/5097 [3:31:08<6:58:38,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1690.json (13528 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  33%|███▎      | 1696/5097 [3:31:46<7:01:04,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1695.json (13568 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  33%|███▎      | 1701/5097 [3:32:23<7:06:57,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1700.json (13608 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  33%|███▎      | 1706/5097 [3:33:00<6:55:52,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1705.json (13648 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  34%|███▎      | 1711/5097 [3:33:38<7:24:23,  7.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1710.json (13688 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  34%|███▎      | 1716/5097 [3:34:16<7:12:01,  7.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1715.json (13728 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  34%|███▍      | 1721/5097 [3:34:53<7:01:54,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1720.json (13768 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  34%|███▍      | 1726/5097 [3:35:30<6:58:04,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1725.json (13808 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  34%|███▍      | 1731/5097 [3:36:07<6:58:18,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1730.json (13848 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  34%|███▍      | 1736/5097 [3:36:45<7:06:33,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1735.json (13888 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  34%|███▍      | 1741/5097 [3:37:23<7:03:07,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1740.json (13928 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  34%|███▍      | 1746/5097 [3:38:00<6:55:20,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1745.json (13968 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  34%|███▍      | 1751/5097 [3:38:38<7:05:38,  7.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1750.json (14008 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  34%|███▍      | 1756/5097 [3:39:16<7:04:10,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1755.json (14048 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  35%|███▍      | 1761/5097 [3:39:53<6:57:17,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1760.json (14088 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  35%|███▍      | 1766/5097 [3:40:30<6:53:54,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1765.json (14128 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  35%|███▍      | 1771/5097 [3:41:07<6:58:35,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1770.json (14168 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  35%|███▍      | 1776/5097 [3:41:44<6:52:56,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1775.json (14208 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  35%|███▍      | 1781/5097 [3:42:22<6:50:43,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1780.json (14248 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  35%|███▌      | 1786/5097 [3:42:58<6:37:54,  7.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1785.json (14288 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  35%|███▌      | 1791/5097 [3:43:35<6:45:03,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1790.json (14328 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  35%|███▌      | 1796/5097 [3:44:12<6:42:53,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1795.json (14368 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  35%|███▌      | 1801/5097 [3:44:50<6:58:49,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1800.json (14408 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  35%|███▌      | 1806/5097 [3:45:25<6:36:52,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1805.json (14448 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  36%|███▌      | 1811/5097 [3:46:02<6:37:43,  7.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1810.json (14488 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  36%|███▌      | 1816/5097 [3:46:40<6:52:56,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1815.json (14528 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  36%|███▌      | 1821/5097 [3:47:16<6:40:22,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1820.json (14568 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  36%|███▌      | 1826/5097 [3:47:54<6:48:32,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1825.json (14608 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  36%|███▌      | 1831/5097 [3:48:30<6:30:58,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1830.json (14648 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  36%|███▌      | 1836/5097 [3:49:07<6:32:56,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1835.json (14688 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  36%|███▌      | 1841/5097 [3:49:43<6:40:48,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1840.json (14728 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  36%|███▌      | 1846/5097 [3:50:20<6:44:47,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1845.json (14768 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  36%|███▋      | 1851/5097 [3:50:57<6:41:23,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1850.json (14808 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  36%|███▋      | 1856/5097 [3:51:34<6:31:49,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1855.json (14848 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  37%|███▋      | 1861/5097 [3:52:11<6:39:19,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1860.json (14888 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  37%|███▋      | 1866/5097 [3:52:48<6:36:27,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1865.json (14928 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  37%|███▋      | 1871/5097 [3:53:25<6:44:14,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1870.json (14968 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  37%|███▋      | 1876/5097 [3:54:02<6:31:19,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1875.json (15008 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  37%|███▋      | 1881/5097 [3:54:39<6:36:45,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1880.json (15048 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  37%|███▋      | 1886/5097 [3:55:16<6:39:49,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1885.json (15088 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  37%|███▋      | 1891/5097 [3:55:54<6:41:59,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1890.json (15128 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  37%|███▋      | 1896/5097 [3:56:31<6:38:03,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1895.json (15168 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  37%|███▋      | 1901/5097 [3:57:09<6:39:12,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1900.json (15208 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  37%|███▋      | 1906/5097 [3:57:46<6:34:04,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1905.json (15248 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  37%|███▋      | 1911/5097 [3:58:22<6:31:02,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1910.json (15288 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  38%|███▊      | 1916/5097 [3:58:59<6:28:22,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1915.json (15328 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  38%|███▊      | 1921/5097 [3:59:36<6:34:43,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1920.json (15368 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  38%|███▊      | 1926/5097 [4:00:13<6:30:37,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1925.json (15408 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  38%|███▊      | 1931/5097 [4:00:50<6:30:20,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1930.json (15448 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  38%|███▊      | 1936/5097 [4:01:27<6:31:10,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1935.json (15488 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  38%|███▊      | 1941/5097 [4:02:05<6:35:50,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1940.json (15528 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  38%|███▊      | 1946/5097 [4:02:41<6:23:58,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1945.json (15568 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  38%|███▊      | 1951/5097 [4:03:18<6:28:55,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1950.json (15608 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  38%|███▊      | 1956/5097 [4:03:55<6:21:55,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1955.json (15648 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  38%|███▊      | 1961/5097 [4:04:31<6:25:51,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1960.json (15688 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  39%|███▊      | 1966/5097 [4:05:08<6:27:23,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1965.json (15728 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  39%|███▊      | 1971/5097 [4:05:45<6:20:30,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1970.json (15768 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  39%|███▉      | 1976/5097 [4:06:24<6:43:52,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1975.json (15808 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  39%|███▉      | 1981/5097 [4:07:01<6:30:39,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1980.json (15848 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  39%|███▉      | 1986/5097 [4:07:38<6:25:08,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1985.json (15888 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  39%|███▉      | 1991/5097 [4:08:15<6:23:27,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1990.json (15928 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  39%|███▉      | 1996/5097 [4:08:51<6:20:47,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_1995.json (15968 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  39%|███▉      | 2001/5097 [4:09:29<6:21:35,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2000.json (16008 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  39%|███▉      | 2006/5097 [4:10:05<6:23:20,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2005.json (16048 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  39%|███▉      | 2011/5097 [4:10:43<6:23:35,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2010.json (16088 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  40%|███▉      | 2016/5097 [4:11:20<6:26:09,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2015.json (16128 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  40%|███▉      | 2021/5097 [4:11:57<6:19:55,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2020.json (16168 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  40%|███▉      | 2026/5097 [4:12:34<6:26:03,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2025.json (16208 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  40%|███▉      | 2031/5097 [4:13:11<6:26:21,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2030.json (16248 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  40%|███▉      | 2036/5097 [4:13:48<6:21:08,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2035.json (16288 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  40%|████      | 2041/5097 [4:14:26<6:24:18,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2040.json (16328 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  40%|████      | 2046/5097 [4:15:03<6:14:29,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2045.json (16368 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  40%|████      | 2051/5097 [4:15:40<6:13:55,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2050.json (16408 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  40%|████      | 2056/5097 [4:16:16<6:10:36,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2055.json (16448 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  40%|████      | 2061/5097 [4:16:54<6:20:50,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2060.json (16488 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  41%|████      | 2066/5097 [4:17:31<6:13:40,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2065.json (16528 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  41%|████      | 2071/5097 [4:18:08<6:14:16,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2070.json (16568 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  41%|████      | 2076/5097 [4:18:44<6:13:53,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2075.json (16608 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  41%|████      | 2081/5097 [4:19:20<6:02:41,  7.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2080.json (16648 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  41%|████      | 2086/5097 [4:19:57<6:00:21,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2085.json (16688 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  41%|████      | 2091/5097 [4:20:33<6:00:39,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2090.json (16728 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  41%|████      | 2096/5097 [4:21:09<6:05:48,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2095.json (16768 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  41%|████      | 2101/5097 [4:21:46<6:07:57,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2100.json (16808 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  41%|████▏     | 2106/5097 [4:22:22<6:00:44,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2105.json (16848 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  41%|████▏     | 2111/5097 [4:22:59<6:07:06,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2110.json (16888 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  42%|████▏     | 2116/5097 [4:23:37<6:17:42,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2115.json (16928 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  42%|████▏     | 2121/5097 [4:24:14<6:01:46,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2120.json (16968 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  42%|████▏     | 2126/5097 [4:24:50<6:00:42,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2125.json (17008 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  42%|████▏     | 2131/5097 [4:25:27<6:07:01,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2130.json (17048 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  42%|████▏     | 2136/5097 [4:26:04<6:07:31,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2135.json (17088 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  42%|████▏     | 2141/5097 [4:26:40<6:01:28,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2140.json (17128 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  42%|████▏     | 2146/5097 [4:27:17<6:07:17,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2145.json (17168 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  42%|████▏     | 2151/5097 [4:27:55<6:09:52,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2150.json (17208 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  42%|████▏     | 2156/5097 [4:28:32<5:59:08,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2155.json (17248 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  42%|████▏     | 2161/5097 [4:29:09<6:04:14,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2160.json (17288 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  42%|████▏     | 2166/5097 [4:29:47<6:05:39,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2165.json (17328 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  43%|████▎     | 2171/5097 [4:30:24<6:02:48,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2170.json (17368 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  43%|████▎     | 2176/5097 [4:31:00<5:51:39,  7.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2175.json (17408 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  43%|████▎     | 2181/5097 [4:31:37<5:57:57,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2180.json (17448 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  43%|████▎     | 2186/5097 [4:32:15<6:01:00,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2185.json (17488 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  43%|████▎     | 2191/5097 [4:32:52<6:00:24,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2190.json (17528 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  43%|████▎     | 2196/5097 [4:33:28<5:48:07,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2195.json (17568 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  43%|████▎     | 2201/5097 [4:34:05<5:45:49,  7.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2200.json (17608 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  43%|████▎     | 2206/5097 [4:34:41<5:52:31,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2205.json (17648 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  43%|████▎     | 2211/5097 [4:35:19<6:04:14,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2210.json (17688 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  43%|████▎     | 2216/5097 [4:35:57<5:59:56,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2215.json (17728 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  44%|████▎     | 2221/5097 [4:36:34<5:58:57,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2220.json (17768 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  44%|████▎     | 2226/5097 [4:37:11<5:53:44,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2225.json (17808 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  44%|████▍     | 2231/5097 [4:37:48<5:53:14,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2230.json (17848 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  44%|████▍     | 2236/5097 [4:38:25<5:57:34,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2235.json (17888 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  44%|████▍     | 2241/5097 [4:39:01<5:37:21,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2240.json (17928 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  44%|████▍     | 2246/5097 [4:39:37<5:45:00,  7.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2245.json (17968 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  44%|████▍     | 2251/5097 [4:40:14<5:47:58,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2250.json (18008 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  44%|████▍     | 2256/5097 [4:40:51<5:43:34,  7.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2255.json (18048 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  44%|████▍     | 2261/5097 [4:41:28<5:53:15,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2260.json (18088 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  44%|████▍     | 2266/5097 [4:42:05<5:47:51,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2265.json (18128 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  45%|████▍     | 2271/5097 [4:42:41<5:45:30,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2270.json (18168 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  45%|████▍     | 2276/5097 [4:43:19<5:53:14,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2275.json (18208 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  45%|████▍     | 2281/5097 [4:43:56<5:48:05,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2280.json (18248 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  45%|████▍     | 2286/5097 [4:44:32<5:37:27,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2285.json (18288 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  45%|████▍     | 2291/5097 [4:45:09<5:43:57,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2290.json (18328 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  45%|████▌     | 2296/5097 [4:45:46<5:43:48,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2295.json (18368 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  45%|████▌     | 2301/5097 [4:46:22<5:38:38,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2300.json (18408 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  45%|████▌     | 2306/5097 [4:46:59<5:40:38,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2305.json (18448 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  45%|████▌     | 2311/5097 [4:47:36<5:47:01,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2310.json (18488 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  45%|████▌     | 2316/5097 [4:48:13<5:42:56,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2315.json (18528 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  46%|████▌     | 2321/5097 [4:48:50<5:39:43,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2320.json (18568 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  46%|████▌     | 2326/5097 [4:49:26<5:39:14,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2325.json (18608 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  46%|████▌     | 2331/5097 [4:50:03<5:31:49,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2330.json (18648 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  46%|████▌     | 2336/5097 [4:50:40<5:41:57,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2335.json (18688 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  46%|████▌     | 2341/5097 [4:51:19<5:50:34,  7.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2340.json (18728 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  46%|████▌     | 2346/5097 [4:51:55<5:37:55,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2345.json (18768 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  46%|████▌     | 2351/5097 [4:52:34<5:54:22,  7.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2350.json (18808 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  46%|████▌     | 2356/5097 [4:53:11<5:40:07,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2355.json (18848 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  46%|████▋     | 2361/5097 [4:53:48<5:36:45,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2360.json (18888 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  46%|████▋     | 2366/5097 [4:54:25<5:36:51,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2365.json (18928 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  47%|████▋     | 2371/5097 [4:55:02<5:30:34,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2370.json (18968 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  47%|████▋     | 2376/5097 [4:55:38<5:25:44,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2375.json (19008 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  47%|████▋     | 2381/5097 [4:56:14<5:26:09,  7.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2380.json (19048 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  47%|████▋     | 2386/5097 [4:56:51<5:30:23,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2385.json (19088 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  47%|████▋     | 2391/5097 [4:57:28<5:35:23,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2390.json (19128 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  47%|████▋     | 2396/5097 [4:58:06<5:42:38,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2395.json (19168 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  47%|████▋     | 2401/5097 [4:58:44<5:38:47,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2400.json (19208 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  47%|████▋     | 2406/5097 [4:59:21<5:31:59,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2405.json (19248 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  47%|████▋     | 2411/5097 [4:59:57<5:31:43,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2410.json (19288 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  47%|████▋     | 2416/5097 [5:00:34<5:28:19,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2415.json (19328 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  47%|████▋     | 2421/5097 [5:01:10<5:27:29,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2420.json (19368 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  48%|████▊     | 2426/5097 [5:01:48<5:31:07,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2425.json (19408 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  48%|████▊     | 2431/5097 [5:02:25<5:36:22,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2430.json (19448 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  48%|████▊     | 2436/5097 [5:03:03<5:32:12,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2435.json (19488 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  48%|████▊     | 2441/5097 [5:03:39<5:23:01,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2440.json (19528 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  48%|████▊     | 2446/5097 [5:04:17<5:30:56,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2445.json (19568 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  48%|████▊     | 2451/5097 [5:04:54<5:23:02,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2450.json (19608 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  48%|████▊     | 2456/5097 [5:05:31<5:27:42,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2455.json (19648 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  48%|████▊     | 2461/5097 [5:06:08<5:19:50,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2460.json (19688 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  48%|████▊     | 2466/5097 [5:06:45<5:21:06,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2465.json (19728 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  48%|████▊     | 2471/5097 [5:07:22<5:20:14,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2470.json (19768 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  49%|████▊     | 2476/5097 [5:08:00<5:33:36,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2475.json (19808 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  49%|████▊     | 2481/5097 [5:08:37<5:27:20,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2480.json (19848 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  49%|████▉     | 2486/5097 [5:09:13<5:16:06,  7.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2485.json (19888 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  49%|████▉     | 2491/5097 [5:09:50<5:18:39,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2490.json (19928 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  49%|████▉     | 2496/5097 [5:10:27<5:20:00,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2495.json (19968 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  49%|████▉     | 2501/5097 [5:11:04<5:23:14,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2500.json (20008 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  49%|████▉     | 2506/5097 [5:11:41<5:20:04,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2505.json (20048 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  49%|████▉     | 2511/5097 [5:12:18<5:19:26,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2510.json (20088 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  49%|████▉     | 2516/5097 [5:12:56<5:18:04,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2515.json (20128 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  49%|████▉     | 2521/5097 [5:13:34<5:29:27,  7.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2520.json (20168 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  50%|████▉     | 2526/5097 [5:14:12<5:31:52,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2525.json (20208 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  50%|████▉     | 2531/5097 [5:14:49<5:16:04,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2530.json (20248 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  50%|████▉     | 2536/5097 [5:15:27<5:25:21,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2535.json (20288 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  50%|████▉     | 2541/5097 [5:16:04<5:15:25,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2540.json (20328 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  50%|████▉     | 2546/5097 [5:16:41<5:13:14,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2545.json (20368 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  50%|█████     | 2551/5097 [5:17:18<5:14:59,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2550.json (20408 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  50%|█████     | 2556/5097 [5:17:56<5:16:54,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2555.json (20448 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  50%|█████     | 2561/5097 [5:18:33<5:14:40,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2560.json (20488 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  50%|█████     | 2566/5097 [5:19:10<5:11:07,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2565.json (20528 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  50%|█████     | 2571/5097 [5:19:48<5:16:50,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2570.json (20568 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  51%|█████     | 2576/5097 [5:20:26<5:20:22,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2575.json (20608 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  51%|█████     | 2581/5097 [5:21:03<5:10:45,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2580.json (20648 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  51%|█████     | 2586/5097 [5:21:40<5:09:26,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2585.json (20688 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  51%|█████     | 2591/5097 [5:22:16<5:06:30,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2590.json (20728 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  51%|█████     | 2596/5097 [5:22:53<5:08:30,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2595.json (20768 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  51%|█████     | 2601/5097 [5:23:30<5:06:33,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2600.json (20808 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  51%|█████     | 2606/5097 [5:24:07<5:05:49,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2605.json (20848 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  51%|█████     | 2611/5097 [5:24:44<5:03:34,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2610.json (20888 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  51%|█████▏    | 2616/5097 [5:25:20<5:04:19,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2615.json (20928 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  51%|█████▏    | 2621/5097 [5:25:57<5:05:21,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2620.json (20968 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  52%|█████▏    | 2626/5097 [5:26:35<5:09:10,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2625.json (21008 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  52%|█████▏    | 2631/5097 [5:27:12<5:01:23,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2630.json (21048 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  52%|█████▏    | 2636/5097 [5:27:50<5:13:17,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2635.json (21088 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  52%|█████▏    | 2641/5097 [5:28:26<4:58:37,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2640.json (21128 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  52%|█████▏    | 2646/5097 [5:29:03<5:07:17,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2645.json (21168 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  52%|█████▏    | 2651/5097 [5:29:40<5:06:15,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2650.json (21208 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  52%|█████▏    | 2656/5097 [5:30:19<5:05:39,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2655.json (21248 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  52%|█████▏    | 2661/5097 [5:30:56<5:02:28,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2660.json (21288 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  52%|█████▏    | 2666/5097 [5:31:33<4:58:15,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2665.json (21328 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  52%|█████▏    | 2671/5097 [5:32:09<4:51:34,  7.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2670.json (21368 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  53%|█████▎    | 2676/5097 [5:32:45<4:51:03,  7.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2675.json (21408 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  53%|█████▎    | 2681/5097 [5:33:22<4:57:10,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2680.json (21448 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  53%|█████▎    | 2686/5097 [5:33:59<4:58:56,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2685.json (21488 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  53%|█████▎    | 2691/5097 [5:34:35<4:49:11,  7.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2690.json (21528 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  53%|█████▎    | 2696/5097 [5:35:12<4:51:34,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2695.json (21568 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  53%|█████▎    | 2701/5097 [5:35:50<5:01:41,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2700.json (21608 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  53%|█████▎    | 2706/5097 [5:36:26<4:53:00,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2705.json (21648 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  53%|█████▎    | 2711/5097 [5:37:03<4:58:51,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2710.json (21688 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  53%|█████▎    | 2716/5097 [5:37:39<4:48:32,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2715.json (21728 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  53%|█████▎    | 2721/5097 [5:38:16<4:50:41,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2720.json (21768 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  53%|█████▎    | 2726/5097 [5:38:53<4:51:15,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2725.json (21808 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  54%|█████▎    | 2731/5097 [5:39:30<4:53:43,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2730.json (21848 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  54%|█████▎    | 2736/5097 [5:40:07<4:53:17,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2735.json (21888 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  54%|█████▍    | 2741/5097 [5:40:44<4:51:22,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2740.json (21928 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  54%|█████▍    | 2746/5097 [5:41:21<4:51:52,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2745.json (21968 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  54%|█████▍    | 2751/5097 [5:41:58<4:46:15,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2750.json (22008 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  54%|█████▍    | 2756/5097 [5:42:33<4:36:14,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2755.json (22048 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  54%|█████▍    | 2761/5097 [5:43:10<4:43:23,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2760.json (22088 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  54%|█████▍    | 2766/5097 [5:43:46<4:45:48,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2765.json (22128 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  54%|█████▍    | 2771/5097 [5:44:24<4:45:48,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2770.json (22168 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  54%|█████▍    | 2776/5097 [5:45:01<4:45:45,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2775.json (22208 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  55%|█████▍    | 2781/5097 [5:45:38<4:52:12,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2780.json (22248 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  55%|█████▍    | 2786/5097 [5:46:13<4:34:19,  7.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2785.json (22288 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  55%|█████▍    | 2791/5097 [5:46:50<4:39:44,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2790.json (22328 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  55%|█████▍    | 2796/5097 [5:47:27<4:45:04,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2795.json (22368 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  55%|█████▍    | 2801/5097 [5:48:04<4:40:24,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2800.json (22408 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  55%|█████▌    | 2806/5097 [5:48:41<4:38:39,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2805.json (22448 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  55%|█████▌    | 2811/5097 [5:49:18<4:43:17,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2810.json (22488 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  55%|█████▌    | 2816/5097 [5:49:55<4:45:15,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2815.json (22528 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  55%|█████▌    | 2821/5097 [5:50:33<4:45:24,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2820.json (22568 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  55%|█████▌    | 2826/5097 [5:51:11<4:44:38,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2825.json (22608 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  56%|█████▌    | 2831/5097 [5:51:49<4:47:10,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2830.json (22648 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  56%|█████▌    | 2836/5097 [5:52:26<4:40:32,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2835.json (22688 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  56%|█████▌    | 2841/5097 [5:53:04<4:46:06,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2840.json (22728 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  56%|█████▌    | 2846/5097 [5:53:40<4:37:46,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2845.json (22768 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  56%|█████▌    | 2851/5097 [5:54:18<4:43:28,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2850.json (22808 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  56%|█████▌    | 2856/5097 [5:54:56<4:35:45,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2855.json (22848 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  56%|█████▌    | 2861/5097 [5:55:32<4:32:36,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2860.json (22888 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  56%|█████▌    | 2866/5097 [5:56:09<4:33:09,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2865.json (22928 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  56%|█████▋    | 2871/5097 [5:56:44<4:21:57,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2870.json (22968 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  56%|█████▋    | 2876/5097 [5:57:20<4:25:47,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2875.json (23008 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  57%|█████▋    | 2881/5097 [5:57:57<4:31:57,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2880.json (23048 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  57%|█████▋    | 2886/5097 [5:58:34<4:35:06,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2885.json (23088 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  57%|█████▋    | 2891/5097 [5:59:11<4:31:52,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2890.json (23128 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  57%|█████▋    | 2896/5097 [5:59:47<4:25:06,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2895.json (23168 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  57%|█████▋    | 2901/5097 [6:00:24<4:25:51,  7.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2900.json (23208 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  57%|█████▋    | 2906/5097 [6:01:02<4:31:25,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2905.json (23248 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  57%|█████▋    | 2911/5097 [6:01:39<4:33:48,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2910.json (23288 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  57%|█████▋    | 2916/5097 [6:02:17<4:34:32,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2915.json (23328 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  57%|█████▋    | 2921/5097 [6:02:54<4:32:59,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2920.json (23368 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  57%|█████▋    | 2926/5097 [6:03:30<4:20:15,  7.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2925.json (23408 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  58%|█████▊    | 2931/5097 [6:04:07<4:20:29,  7.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2930.json (23448 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  58%|█████▊    | 2936/5097 [6:04:44<4:23:42,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2935.json (23488 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  58%|█████▊    | 2941/5097 [6:05:21<4:21:28,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2940.json (23528 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  58%|█████▊    | 2946/5097 [6:05:57<4:25:01,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2945.json (23568 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  58%|█████▊    | 2951/5097 [6:06:34<4:24:04,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2950.json (23608 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  58%|█████▊    | 2956/5097 [6:07:11<4:24:35,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2955.json (23648 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  58%|█████▊    | 2961/5097 [6:07:48<4:25:39,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2960.json (23688 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  58%|█████▊    | 2966/5097 [6:08:25<4:20:45,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2965.json (23728 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  58%|█████▊    | 2971/5097 [6:09:02<4:20:50,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2970.json (23768 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  58%|█████▊    | 2976/5097 [6:09:39<4:20:53,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2975.json (23808 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  58%|█████▊    | 2981/5097 [6:10:16<4:20:24,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2980.json (23848 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  59%|█████▊    | 2986/5097 [6:10:53<4:19:43,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2985.json (23888 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  59%|█████▊    | 2991/5097 [6:11:30<4:17:42,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2990.json (23928 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  59%|█████▉    | 2996/5097 [6:12:06<4:13:44,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_2995.json (23968 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  59%|█████▉    | 3001/5097 [6:12:43<4:14:27,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3000.json (24008 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  59%|█████▉    | 3006/5097 [6:13:20<4:20:53,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3005.json (24048 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  59%|█████▉    | 3011/5097 [6:13:58<4:23:27,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3010.json (24088 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  59%|█████▉    | 3016/5097 [6:14:34<4:15:43,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3015.json (24128 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  59%|█████▉    | 3021/5097 [6:15:11<4:11:38,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3020.json (24168 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  59%|█████▉    | 3026/5097 [6:15:48<4:18:39,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3025.json (24208 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  59%|█████▉    | 3031/5097 [6:16:25<4:12:02,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3030.json (24248 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  60%|█████▉    | 3036/5097 [6:17:01<4:11:10,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3035.json (24288 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  60%|█████▉    | 3041/5097 [6:17:37<4:04:52,  7.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3040.json (24328 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  60%|█████▉    | 3046/5097 [6:18:14<4:11:32,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3045.json (24368 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  60%|█████▉    | 3051/5097 [6:18:51<4:08:17,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3050.json (24408 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  60%|█████▉    | 3056/5097 [6:19:28<4:10:00,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3055.json (24448 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  60%|██████    | 3061/5097 [6:20:05<4:11:37,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3060.json (24488 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  60%|██████    | 3066/5097 [6:20:42<4:11:37,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3065.json (24528 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  60%|██████    | 3071/5097 [6:21:18<4:08:41,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3070.json (24568 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  60%|██████    | 3076/5097 [6:21:55<4:07:43,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3075.json (24608 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  60%|██████    | 3081/5097 [6:22:33<4:13:39,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3080.json (24648 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  61%|██████    | 3086/5097 [6:23:09<4:03:26,  7.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3085.json (24688 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  61%|██████    | 3091/5097 [6:23:46<4:09:49,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3090.json (24728 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  61%|██████    | 3096/5097 [6:24:24<4:12:44,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3095.json (24768 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  61%|██████    | 3101/5097 [6:25:02<4:09:15,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3100.json (24808 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  61%|██████    | 3106/5097 [6:25:38<4:05:53,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3105.json (24848 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  61%|██████    | 3111/5097 [6:26:15<4:01:41,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3110.json (24888 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  61%|██████    | 3116/5097 [6:26:51<4:04:55,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3115.json (24928 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  61%|██████    | 3121/5097 [6:27:28<4:04:27,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3120.json (24968 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  61%|██████▏   | 3126/5097 [6:28:05<4:03:33,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3125.json (25008 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  61%|██████▏   | 3131/5097 [6:28:42<3:59:47,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3130.json (25048 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  62%|██████▏   | 3136/5097 [6:29:19<4:02:12,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3135.json (25088 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  62%|██████▏   | 3141/5097 [6:29:57<4:04:52,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3140.json (25128 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  62%|██████▏   | 3146/5097 [6:30:33<3:56:38,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3145.json (25168 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  62%|██████▏   | 3151/5097 [6:31:10<4:00:13,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3150.json (25208 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  62%|██████▏   | 3156/5097 [6:31:47<4:01:59,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3155.json (25248 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  62%|██████▏   | 3161/5097 [6:32:25<4:01:32,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3160.json (25288 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  62%|██████▏   | 3166/5097 [6:33:01<4:00:53,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3165.json (25328 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  62%|██████▏   | 3171/5097 [6:33:39<3:59:39,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3170.json (25368 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  62%|██████▏   | 3176/5097 [6:34:18<4:03:48,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3175.json (25408 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  62%|██████▏   | 3181/5097 [6:34:54<3:55:01,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3180.json (25448 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  63%|██████▎   | 3186/5097 [6:35:31<3:58:42,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3185.json (25488 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  63%|██████▎   | 3191/5097 [6:36:09<4:00:48,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3190.json (25528 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  63%|██████▎   | 3196/5097 [6:36:46<3:52:10,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3195.json (25568 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  63%|██████▎   | 3201/5097 [6:37:23<3:57:23,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3200.json (25608 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  63%|██████▎   | 3206/5097 [6:38:00<3:53:08,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3205.json (25648 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  63%|██████▎   | 3211/5097 [6:38:38<3:55:35,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3210.json (25688 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  63%|██████▎   | 3216/5097 [6:39:14<3:45:35,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3215.json (25728 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  63%|██████▎   | 3221/5097 [6:39:51<3:54:15,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3220.json (25768 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  63%|██████▎   | 3226/5097 [6:40:27<3:45:53,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3225.json (25808 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  63%|██████▎   | 3231/5097 [6:41:04<3:49:27,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3230.json (25848 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  63%|██████▎   | 3236/5097 [6:41:40<3:43:20,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3235.json (25888 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  64%|██████▎   | 3241/5097 [6:42:18<3:49:00,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3240.json (25928 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  64%|██████▎   | 3246/5097 [6:42:55<3:49:11,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3245.json (25968 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  64%|██████▍   | 3251/5097 [6:43:32<3:54:10,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3250.json (26008 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  64%|██████▍   | 3256/5097 [6:44:10<3:54:47,  7.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3255.json (26048 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  64%|██████▍   | 3261/5097 [6:44:46<3:43:37,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3260.json (26088 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  64%|██████▍   | 3266/5097 [6:45:24<3:47:04,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3265.json (26128 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  64%|██████▍   | 3271/5097 [6:45:59<3:37:02,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3270.json (26168 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  64%|██████▍   | 3276/5097 [6:46:36<3:43:14,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3275.json (26208 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  64%|██████▍   | 3281/5097 [6:47:14<3:46:00,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3280.json (26248 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  64%|██████▍   | 3286/5097 [6:47:49<3:39:03,  7.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3285.json (26288 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  65%|██████▍   | 3291/5097 [6:48:26<3:41:10,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3290.json (26328 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  65%|██████▍   | 3296/5097 [6:49:04<3:42:00,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3295.json (26368 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  65%|██████▍   | 3301/5097 [6:49:41<3:42:47,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3300.json (26408 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  65%|██████▍   | 3306/5097 [6:50:18<3:39:37,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3305.json (26448 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  65%|██████▍   | 3311/5097 [6:50:55<3:39:52,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3310.json (26488 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  65%|██████▌   | 3316/5097 [6:51:32<3:40:10,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3315.json (26528 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  65%|██████▌   | 3321/5097 [6:52:09<3:43:29,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3320.json (26568 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  65%|██████▌   | 3326/5097 [6:52:47<3:39:59,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3325.json (26608 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  65%|██████▌   | 3331/5097 [6:53:24<3:39:12,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3330.json (26648 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  65%|██████▌   | 3336/5097 [6:54:01<3:36:43,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3335.json (26688 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  66%|██████▌   | 3341/5097 [6:54:37<3:34:42,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3340.json (26728 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  66%|██████▌   | 3346/5097 [6:55:14<3:34:00,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3345.json (26768 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  66%|██████▌   | 3351/5097 [6:55:50<3:33:08,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3350.json (26808 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  66%|██████▌   | 3356/5097 [6:56:27<3:34:54,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3355.json (26848 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  66%|██████▌   | 3361/5097 [6:57:03<3:28:51,  7.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3360.json (26888 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  66%|██████▌   | 3366/5097 [6:57:40<3:32:45,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3365.json (26928 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  66%|██████▌   | 3371/5097 [6:58:17<3:31:58,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3370.json (26968 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  66%|██████▌   | 3376/5097 [6:58:54<3:33:27,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3375.json (27008 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  66%|██████▋   | 3381/5097 [6:59:32<3:31:51,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3380.json (27048 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  66%|██████▋   | 3386/5097 [7:00:09<3:33:02,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3385.json (27088 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  67%|██████▋   | 3391/5097 [7:00:46<3:33:05,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3390.json (27128 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  67%|██████▋   | 3396/5097 [7:01:24<3:32:10,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3395.json (27168 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  67%|██████▋   | 3401/5097 [7:02:01<3:25:50,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3400.json (27208 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  67%|██████▋   | 3406/5097 [7:02:37<3:26:42,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3405.json (27248 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  67%|██████▋   | 3411/5097 [7:03:14<3:26:55,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3410.json (27288 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  67%|██████▋   | 3416/5097 [7:03:51<3:26:40,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3415.json (27328 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  67%|██████▋   | 3421/5097 [7:04:28<3:27:40,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3420.json (27368 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  67%|██████▋   | 3426/5097 [7:05:06<3:27:44,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3425.json (27408 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  67%|██████▋   | 3431/5097 [7:05:43<3:26:47,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3430.json (27448 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  67%|██████▋   | 3436/5097 [7:06:20<3:27:28,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3435.json (27488 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  68%|██████▊   | 3441/5097 [7:06:57<3:24:15,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3440.json (27528 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  68%|██████▊   | 3446/5097 [7:07:34<3:22:59,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3445.json (27568 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  68%|██████▊   | 3451/5097 [7:08:11<3:23:02,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3450.json (27608 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  68%|██████▊   | 3456/5097 [7:08:48<3:23:54,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3455.json (27648 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  68%|██████▊   | 3461/5097 [7:09:26<3:24:00,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3460.json (27688 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  68%|██████▊   | 3466/5097 [7:10:03<3:22:33,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3465.json (27728 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  68%|██████▊   | 3471/5097 [7:10:40<3:21:52,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3470.json (27768 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  68%|██████▊   | 3476/5097 [7:11:17<3:19:46,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3475.json (27808 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  68%|██████▊   | 3481/5097 [7:11:53<3:16:06,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3480.json (27848 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  68%|██████▊   | 3486/5097 [7:12:30<3:22:18,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3485.json (27888 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  68%|██████▊   | 3491/5097 [7:13:07<3:18:00,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3490.json (27928 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  69%|██████▊   | 3496/5097 [7:13:45<3:18:54,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3495.json (27968 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  69%|██████▊   | 3501/5097 [7:14:21<3:15:02,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3500.json (28008 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  69%|██████▉   | 3506/5097 [7:14:58<3:17:17,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3505.json (28048 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  69%|██████▉   | 3511/5097 [7:15:35<3:18:21,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3510.json (28088 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  69%|██████▉   | 3516/5097 [7:16:12<3:12:57,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3515.json (28128 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  69%|██████▉   | 3521/5097 [7:16:48<3:13:23,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3520.json (28168 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  69%|██████▉   | 3526/5097 [7:17:25<3:13:46,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3525.json (28208 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  69%|██████▉   | 3531/5097 [7:18:02<3:15:40,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3530.json (28248 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  69%|██████▉   | 3536/5097 [7:18:38<3:10:14,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3535.json (28288 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  69%|██████▉   | 3541/5097 [7:19:15<3:12:36,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3540.json (28328 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  70%|██████▉   | 3546/5097 [7:19:52<3:08:12,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3545.json (28368 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  70%|██████▉   | 3551/5097 [7:20:29<3:10:58,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3550.json (28408 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  70%|██████▉   | 3556/5097 [7:21:05<3:06:29,  7.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3555.json (28448 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  70%|██████▉   | 3561/5097 [7:21:43<3:11:39,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3560.json (28488 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  70%|██████▉   | 3566/5097 [7:22:20<3:11:39,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3565.json (28528 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  70%|███████   | 3571/5097 [7:22:57<3:04:51,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3570.json (28568 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  70%|███████   | 3576/5097 [7:23:34<3:05:20,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3575.json (28608 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  70%|███████   | 3581/5097 [7:24:10<3:07:35,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3580.json (28648 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  70%|███████   | 3586/5097 [7:24:46<3:02:02,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3585.json (28688 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  70%|███████   | 3591/5097 [7:25:23<3:03:04,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3590.json (28728 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  71%|███████   | 3596/5097 [7:26:00<3:04:30,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3595.json (28768 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  71%|███████   | 3601/5097 [7:26:37<3:05:37,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3600.json (28808 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  71%|███████   | 3606/5097 [7:27:13<3:01:03,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3605.json (28848 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  71%|███████   | 3611/5097 [7:27:51<3:03:31,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3610.json (28888 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  71%|███████   | 3616/5097 [7:28:27<2:59:16,  7.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3615.json (28928 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  71%|███████   | 3621/5097 [7:29:04<3:03:22,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3620.json (28968 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  71%|███████   | 3626/5097 [7:29:42<3:01:46,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3625.json (29008 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  71%|███████   | 3631/5097 [7:30:18<3:00:34,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3630.json (29048 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  71%|███████▏  | 3636/5097 [7:30:56<3:02:38,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3635.json (29088 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  71%|███████▏  | 3641/5097 [7:31:32<3:00:21,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3640.json (29128 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  72%|███████▏  | 3646/5097 [7:32:09<2:55:25,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3645.json (29168 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  72%|███████▏  | 3651/5097 [7:32:45<2:56:24,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3650.json (29208 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  72%|███████▏  | 3656/5097 [7:33:22<2:59:24,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3655.json (29248 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  72%|███████▏  | 3661/5097 [7:33:59<2:56:43,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3660.json (29288 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  72%|███████▏  | 3666/5097 [7:34:37<2:56:43,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3665.json (29328 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  72%|███████▏  | 3671/5097 [7:35:14<2:57:15,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3670.json (29368 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  72%|███████▏  | 3676/5097 [7:35:51<2:53:48,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3675.json (29408 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  72%|███████▏  | 3681/5097 [7:36:27<2:54:06,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3680.json (29448 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  72%|███████▏  | 3686/5097 [7:37:04<2:53:35,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3685.json (29488 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  72%|███████▏  | 3691/5097 [7:37:42<2:56:48,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3690.json (29528 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  73%|███████▎  | 3696/5097 [7:38:19<2:51:34,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3695.json (29568 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  73%|███████▎  | 3701/5097 [7:38:56<2:52:50,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3700.json (29608 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  73%|███████▎  | 3706/5097 [7:39:34<2:55:09,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3705.json (29648 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  73%|███████▎  | 3711/5097 [7:40:11<2:53:09,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3710.json (29688 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  73%|███████▎  | 3716/5097 [7:40:48<2:50:51,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3715.json (29728 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  73%|███████▎  | 3721/5097 [7:41:24<2:46:08,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3720.json (29768 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  73%|███████▎  | 3726/5097 [7:42:01<2:47:46,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3725.json (29808 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  73%|███████▎  | 3731/5097 [7:42:38<2:47:27,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3730.json (29848 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  73%|███████▎  | 3736/5097 [7:43:14<2:44:00,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3735.json (29888 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  73%|███████▎  | 3741/5097 [7:43:52<2:51:21,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3740.json (29928 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  73%|███████▎  | 3746/5097 [7:44:29<2:47:52,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3745.json (29968 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  74%|███████▎  | 3751/5097 [7:45:06<2:45:13,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3750.json (30008 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  74%|███████▎  | 3756/5097 [7:45:43<2:45:21,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3755.json (30048 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  74%|███████▍  | 3761/5097 [7:46:20<2:44:09,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3760.json (30088 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  74%|███████▍  | 3766/5097 [7:46:56<2:40:40,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3765.json (30128 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  74%|███████▍  | 3771/5097 [7:47:33<2:44:41,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3770.json (30168 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  74%|███████▍  | 3776/5097 [7:48:11<2:45:40,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3775.json (30208 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  74%|███████▍  | 3781/5097 [7:48:47<2:41:03,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3780.json (30248 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  74%|███████▍  | 3786/5097 [7:49:23<2:41:44,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3785.json (30288 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  74%|███████▍  | 3791/5097 [7:50:01<2:41:29,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3790.json (30328 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  74%|███████▍  | 3796/5097 [7:50:37<2:36:50,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3795.json (30368 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  75%|███████▍  | 3801/5097 [7:51:14<2:39:28,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3800.json (30408 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  75%|███████▍  | 3806/5097 [7:51:52<2:43:59,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3805.json (30448 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  75%|███████▍  | 3811/5097 [7:52:30<2:42:58,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3810.json (30488 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  75%|███████▍  | 3816/5097 [7:53:07<2:38:09,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3815.json (30528 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  75%|███████▍  | 3821/5097 [7:53:44<2:38:57,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3820.json (30568 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  75%|███████▌  | 3826/5097 [7:54:22<2:38:02,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3825.json (30608 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  75%|███████▌  | 3831/5097 [7:54:59<2:40:54,  7.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3830.json (30648 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  75%|███████▌  | 3836/5097 [7:55:37<2:39:34,  7.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3835.json (30688 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  75%|███████▌  | 3841/5097 [7:56:14<2:36:13,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3840.json (30728 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  75%|███████▌  | 3846/5097 [7:56:51<2:33:56,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3845.json (30768 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  76%|███████▌  | 3851/5097 [7:57:28<2:35:01,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3850.json (30808 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  76%|███████▌  | 3856/5097 [7:58:05<2:34:33,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3855.json (30848 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  76%|███████▌  | 3861/5097 [7:58:41<2:29:25,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3860.json (30888 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  76%|███████▌  | 3866/5097 [7:59:18<2:30:40,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3865.json (30928 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  76%|███████▌  | 3871/5097 [7:59:54<2:29:33,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3870.json (30968 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  76%|███████▌  | 3876/5097 [8:00:32<2:30:53,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3875.json (31008 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  76%|███████▌  | 3881/5097 [8:01:08<2:30:23,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3880.json (31048 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  76%|███████▌  | 3886/5097 [8:01:46<2:30:47,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3885.json (31088 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  76%|███████▋  | 3891/5097 [8:02:22<2:26:45,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3890.json (31128 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  76%|███████▋  | 3896/5097 [8:03:00<2:29:20,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3895.json (31168 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  77%|███████▋  | 3901/5097 [8:03:36<2:25:47,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3900.json (31208 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  77%|███████▋  | 3906/5097 [8:04:13<2:26:29,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3905.json (31248 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  77%|███████▋  | 3911/5097 [8:04:51<2:26:59,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3910.json (31288 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  77%|███████▋  | 3916/5097 [8:05:28<2:26:10,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3915.json (31328 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  77%|███████▋  | 3921/5097 [8:06:05<2:24:52,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3920.json (31368 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  77%|███████▋  | 3926/5097 [8:06:42<2:24:30,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3925.json (31408 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  77%|███████▋  | 3931/5097 [8:07:19<2:23:08,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3930.json (31448 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  77%|███████▋  | 3936/5097 [8:07:55<2:21:29,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3935.json (31488 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  77%|███████▋  | 3941/5097 [8:08:33<2:23:10,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3940.json (31528 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  77%|███████▋  | 3946/5097 [8:09:09<2:19:15,  7.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3945.json (31568 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  78%|███████▊  | 3951/5097 [8:09:45<2:19:30,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3950.json (31608 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  78%|███████▊  | 3956/5097 [8:10:23<2:21:15,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3955.json (31648 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  78%|███████▊  | 3961/5097 [8:10:59<2:18:59,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3960.json (31688 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  78%|███████▊  | 3966/5097 [8:11:35<2:16:28,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3965.json (31728 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  78%|███████▊  | 3971/5097 [8:12:12<2:20:01,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3970.json (31768 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  78%|███████▊  | 3976/5097 [8:12:49<2:17:01,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3975.json (31808 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  78%|███████▊  | 3981/5097 [8:13:25<2:15:57,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3980.json (31848 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  78%|███████▊  | 3986/5097 [8:14:03<2:18:25,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3985.json (31888 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  78%|███████▊  | 3991/5097 [8:14:41<2:18:05,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3990.json (31928 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  78%|███████▊  | 3996/5097 [8:15:17<2:13:19,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_3995.json (31968 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  78%|███████▊  | 4001/5097 [8:15:54<2:15:01,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4000.json (32008 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  79%|███████▊  | 4006/5097 [8:16:32<2:14:13,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4005.json (32048 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  79%|███████▊  | 4011/5097 [8:17:08<2:10:24,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4010.json (32088 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  79%|███████▉  | 4016/5097 [8:17:45<2:14:56,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4015.json (32128 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  79%|███████▉  | 4021/5097 [8:18:22<2:15:29,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4020.json (32168 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  79%|███████▉  | 4026/5097 [8:18:59<2:12:47,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4025.json (32208 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  79%|███████▉  | 4031/5097 [8:19:38<2:16:49,  7.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4030.json (32248 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  79%|███████▉  | 4036/5097 [8:20:14<2:11:22,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4035.json (32288 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  79%|███████▉  | 4041/5097 [8:20:52<2:13:20,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4040.json (32328 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  79%|███████▉  | 4046/5097 [8:21:29<2:08:55,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4045.json (32368 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  79%|███████▉  | 4051/5097 [8:22:06<2:08:29,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4050.json (32408 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  80%|███████▉  | 4056/5097 [8:22:43<2:08:31,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4055.json (32448 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  80%|███████▉  | 4061/5097 [8:23:21<2:08:37,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4060.json (32488 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  80%|███████▉  | 4066/5097 [8:23:57<2:05:16,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4065.json (32528 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  80%|███████▉  | 4071/5097 [8:24:34<2:07:38,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4070.json (32568 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  80%|███████▉  | 4076/5097 [8:25:12<2:05:05,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4075.json (32608 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  80%|████████  | 4081/5097 [8:25:49<2:07:28,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4080.json (32648 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  80%|████████  | 4086/5097 [8:26:27<2:08:52,  7.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4085.json (32688 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  80%|████████  | 4091/5097 [8:27:04<2:03:55,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4090.json (32728 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  80%|████████  | 4096/5097 [8:27:41<2:00:55,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4095.json (32768 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  80%|████████  | 4101/5097 [8:28:18<2:04:40,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4100.json (32808 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  81%|████████  | 4106/5097 [8:28:55<2:02:15,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4105.json (32848 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  81%|████████  | 4111/5097 [8:29:32<2:02:10,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4110.json (32888 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  81%|████████  | 4116/5097 [8:30:09<2:00:19,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4115.json (32928 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  81%|████████  | 4121/5097 [8:30:46<2:00:43,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4120.json (32968 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  81%|████████  | 4126/5097 [8:31:23<1:58:15,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4125.json (33008 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  81%|████████  | 4131/5097 [8:32:00<1:59:01,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4130.json (33048 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  81%|████████  | 4136/5097 [8:32:37<1:59:57,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4135.json (33088 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  81%|████████  | 4141/5097 [8:33:13<1:54:35,  7.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4140.json (33128 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  81%|████████▏ | 4146/5097 [8:33:52<2:03:00,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4145.json (33168 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  81%|████████▏ | 4151/5097 [8:34:29<1:56:25,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4150.json (33208 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  82%|████████▏ | 4156/5097 [8:35:06<1:58:22,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4155.json (33248 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  82%|████████▏ | 4161/5097 [8:35:44<1:57:11,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4160.json (33288 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  82%|████████▏ | 4166/5097 [8:36:21<1:56:15,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4165.json (33328 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  82%|████████▏ | 4171/5097 [8:36:59<1:57:00,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4170.json (33368 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  82%|████████▏ | 4176/5097 [8:37:36<1:53:21,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4175.json (33408 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  82%|████████▏ | 4181/5097 [8:38:14<1:54:28,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4180.json (33448 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  82%|████████▏ | 4186/5097 [8:38:52<1:55:50,  7.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4185.json (33488 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  82%|████████▏ | 4191/5097 [8:39:29<1:52:06,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4190.json (33528 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  82%|████████▏ | 4196/5097 [8:40:07<1:51:54,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4195.json (33568 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  82%|████████▏ | 4201/5097 [8:40:44<1:49:52,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4200.json (33608 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  83%|████████▎ | 4206/5097 [8:41:20<1:49:26,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4205.json (33648 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  83%|████████▎ | 4211/5097 [8:41:58<1:51:17,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4210.json (33688 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  83%|████████▎ | 4216/5097 [8:42:34<1:49:08,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4215.json (33728 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  83%|████████▎ | 4221/5097 [8:43:12<1:49:47,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4220.json (33768 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  83%|████████▎ | 4226/5097 [8:43:49<1:47:32,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4225.json (33808 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  83%|████████▎ | 4231/5097 [8:44:27<1:48:00,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4230.json (33848 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  83%|████████▎ | 4236/5097 [8:45:04<1:46:54,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4235.json (33888 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  83%|████████▎ | 4241/5097 [8:45:40<1:44:29,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4240.json (33928 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  83%|████████▎ | 4246/5097 [8:46:17<1:44:06,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4245.json (33968 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  83%|████████▎ | 4251/5097 [8:46:54<1:45:46,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4250.json (34008 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  84%|████████▎ | 4256/5097 [8:47:32<1:47:38,  7.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4255.json (34048 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  84%|████████▎ | 4261/5097 [8:48:10<1:45:39,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4260.json (34088 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  84%|████████▎ | 4266/5097 [8:48:47<1:42:24,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4265.json (34128 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  84%|████████▍ | 4271/5097 [8:49:24<1:42:24,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4270.json (34168 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  84%|████████▍ | 4276/5097 [8:50:01<1:41:13,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4275.json (34208 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  84%|████████▍ | 4281/5097 [8:50:37<1:39:15,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4280.json (34248 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  84%|████████▍ | 4286/5097 [8:51:15<1:41:59,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4285.json (34288 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  84%|████████▍ | 4291/5097 [8:51:52<1:39:54,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4290.json (34328 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  84%|████████▍ | 4296/5097 [8:52:28<1:36:34,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4295.json (34368 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  84%|████████▍ | 4301/5097 [8:53:04<1:35:50,  7.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4300.json (34408 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  84%|████████▍ | 4306/5097 [8:53:42<1:39:16,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4305.json (34448 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  85%|████████▍ | 4311/5097 [8:54:19<1:36:56,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4310.json (34488 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  85%|████████▍ | 4316/5097 [8:54:56<1:36:40,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4315.json (34528 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  85%|████████▍ | 4321/5097 [8:55:34<1:37:24,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4320.json (34568 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  85%|████████▍ | 4326/5097 [8:56:11<1:36:31,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4325.json (34608 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  85%|████████▍ | 4331/5097 [8:56:48<1:35:11,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4330.json (34648 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  85%|████████▌ | 4336/5097 [8:57:26<1:34:43,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4335.json (34688 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  85%|████████▌ | 4341/5097 [8:58:02<1:33:30,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4340.json (34728 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  85%|████████▌ | 4346/5097 [8:58:39<1:32:03,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4345.json (34768 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  85%|████████▌ | 4351/5097 [8:59:16<1:32:24,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4350.json (34808 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  85%|████████▌ | 4356/5097 [8:59:53<1:30:33,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4355.json (34848 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  86%|████████▌ | 4361/5097 [9:00:30<1:31:23,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4360.json (34888 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  86%|████████▌ | 4366/5097 [9:01:07<1:28:37,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4365.json (34928 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  86%|████████▌ | 4371/5097 [9:01:44<1:29:20,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4370.json (34968 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  86%|████████▌ | 4376/5097 [9:02:22<1:28:29,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4375.json (35008 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  86%|████████▌ | 4381/5097 [9:02:59<1:29:22,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4380.json (35048 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  86%|████████▌ | 4386/5097 [9:03:37<1:30:08,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4385.json (35088 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  86%|████████▌ | 4391/5097 [9:04:14<1:27:54,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4390.json (35128 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  86%|████████▌ | 4396/5097 [9:04:51<1:25:23,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4395.json (35168 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  86%|████████▋ | 4401/5097 [9:05:28<1:26:23,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4400.json (35208 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  86%|████████▋ | 4406/5097 [9:06:05<1:24:00,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4405.json (35248 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  87%|████████▋ | 4411/5097 [9:06:41<1:23:55,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4410.json (35288 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  87%|████████▋ | 4416/5097 [9:07:17<1:20:50,  7.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4415.json (35328 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  87%|████████▋ | 4421/5097 [9:07:53<1:22:23,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4420.json (35368 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  87%|████████▋ | 4426/5097 [9:08:30<1:22:46,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4425.json (35408 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  87%|████████▋ | 4431/5097 [9:09:07<1:22:06,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4430.json (35448 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  87%|████████▋ | 4436/5097 [9:09:44<1:21:50,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4435.json (35488 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  87%|████████▋ | 4441/5097 [9:10:21<1:20:37,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4440.json (35528 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  87%|████████▋ | 4446/5097 [9:10:57<1:19:16,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4445.json (35568 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  87%|████████▋ | 4451/5097 [9:11:35<1:20:04,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4450.json (35608 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  87%|████████▋ | 4456/5097 [9:12:12<1:18:28,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4455.json (35648 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  88%|████████▊ | 4461/5097 [9:12:50<1:20:34,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4460.json (35688 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  88%|████████▊ | 4466/5097 [9:13:27<1:19:00,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4465.json (35728 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  88%|████████▊ | 4471/5097 [9:14:04<1:17:28,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4470.json (35768 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  88%|████████▊ | 4476/5097 [9:14:41<1:16:31,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4475.json (35808 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  88%|████████▊ | 4481/5097 [9:15:18<1:16:23,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4480.json (35848 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  88%|████████▊ | 4486/5097 [9:15:55<1:16:36,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4485.json (35888 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  88%|████████▊ | 4491/5097 [9:16:32<1:14:58,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4490.json (35928 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  88%|████████▊ | 4496/5097 [9:17:10<1:14:29,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4495.json (35968 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  88%|████████▊ | 4501/5097 [9:17:47<1:14:07,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4500.json (36008 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  88%|████████▊ | 4506/5097 [9:18:24<1:12:41,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4505.json (36048 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  89%|████████▊ | 4511/5097 [9:19:01<1:12:16,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4510.json (36088 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  89%|████████▊ | 4516/5097 [9:19:38<1:12:02,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4515.json (36128 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  89%|████████▊ | 4521/5097 [9:20:16<1:12:32,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4520.json (36168 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  89%|████████▉ | 4526/5097 [9:20:52<1:08:44,  7.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4525.json (36208 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  89%|████████▉ | 4531/5097 [9:21:29<1:09:11,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4530.json (36248 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  89%|████████▉ | 4536/5097 [9:22:06<1:06:33,  7.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4535.json (36288 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  89%|████████▉ | 4541/5097 [9:22:42<1:08:06,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4540.json (36328 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  89%|████████▉ | 4546/5097 [9:23:18<1:06:18,  7.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4545.json (36368 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  89%|████████▉ | 4551/5097 [9:23:54<1:06:12,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4550.json (36408 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  89%|████████▉ | 4556/5097 [9:24:31<1:07:00,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4555.json (36448 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  89%|████████▉ | 4561/5097 [9:25:07<1:04:31,  7.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4560.json (36488 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  90%|████████▉ | 4566/5097 [9:25:45<1:06:21,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4565.json (36528 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  90%|████████▉ | 4571/5097 [9:26:22<1:04:54,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4570.json (36568 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  90%|████████▉ | 4576/5097 [9:26:59<1:03:34,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4575.json (36608 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  90%|████████▉ | 4581/5097 [9:27:37<1:04:19,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4580.json (36648 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  90%|████████▉ | 4586/5097 [9:28:13<1:02:10,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4585.json (36688 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  90%|█████████ | 4591/5097 [9:28:50<1:03:23,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4590.json (36728 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  90%|█████████ | 4596/5097 [9:29:28<1:02:02,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4595.json (36768 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  90%|█████████ | 4601/5097 [9:30:05<1:01:17,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4600.json (36808 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  90%|█████████ | 4606/5097 [9:30:42<1:00:35,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4605.json (36848 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  90%|█████████ | 4611/5097 [9:31:19<59:54,  7.40s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4610.json (36888 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  91%|█████████ | 4616/5097 [9:31:56<1:00:12,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4615.json (36928 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  91%|█████████ | 4621/5097 [9:32:34<59:04,  7.45s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4620.json (36968 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  91%|█████████ | 4626/5097 [9:33:12<59:11,  7.54s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4625.json (37008 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  91%|█████████ | 4631/5097 [9:33:48<56:19,  7.25s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4630.json (37048 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  91%|█████████ | 4636/5097 [9:34:27<58:26,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4635.json (37088 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  91%|█████████ | 4641/5097 [9:35:04<56:41,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4640.json (37128 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  91%|█████████ | 4646/5097 [9:35:42<55:16,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4645.json (37168 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  91%|█████████ | 4651/5097 [9:36:18<54:19,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4650.json (37208 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  91%|█████████▏| 4656/5097 [9:36:55<54:34,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4655.json (37248 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  91%|█████████▏| 4661/5097 [9:37:32<53:44,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4660.json (37288 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  92%|█████████▏| 4666/5097 [9:38:09<52:29,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4665.json (37328 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  92%|█████████▏| 4671/5097 [9:38:45<51:27,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4670.json (37368 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  92%|█████████▏| 4676/5097 [9:39:23<52:05,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4675.json (37408 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  92%|█████████▏| 4681/5097 [9:40:00<52:08,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4680.json (37448 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  92%|█████████▏| 4686/5097 [9:40:37<51:16,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4685.json (37488 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  92%|█████████▏| 4691/5097 [9:41:14<49:20,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4690.json (37528 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  92%|█████████▏| 4696/5097 [9:41:50<48:26,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4695.json (37568 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  92%|█████████▏| 4701/5097 [9:42:27<49:01,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4700.json (37608 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  92%|█████████▏| 4706/5097 [9:43:04<48:36,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4705.json (37648 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  92%|█████████▏| 4711/5097 [9:43:42<47:47,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4710.json (37688 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  93%|█████████▎| 4716/5097 [9:44:19<47:09,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4715.json (37728 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  93%|█████████▎| 4721/5097 [9:44:57<48:19,  7.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4720.json (37768 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  93%|█████████▎| 4726/5097 [9:45:34<46:09,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4725.json (37808 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  93%|█████████▎| 4731/5097 [9:46:12<45:45,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4730.json (37848 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  93%|█████████▎| 4736/5097 [9:46:50<44:45,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4735.json (37888 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  93%|█████████▎| 4741/5097 [9:47:26<43:12,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4740.json (37928 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  93%|█████████▎| 4746/5097 [9:48:03<42:48,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4745.json (37968 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  93%|█████████▎| 4751/5097 [9:48:40<43:13,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4750.json (38008 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  93%|█████████▎| 4756/5097 [9:49:18<43:01,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4755.json (38048 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  93%|█████████▎| 4761/5097 [9:49:55<41:15,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4760.json (38088 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  94%|█████████▎| 4766/5097 [9:50:31<40:15,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4765.json (38128 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  94%|█████████▎| 4771/5097 [9:51:09<40:45,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4770.json (38168 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  94%|█████████▎| 4776/5097 [9:51:46<40:28,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4775.json (38208 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  94%|█████████▍| 4781/5097 [9:52:23<38:54,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4780.json (38248 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  94%|█████████▍| 4786/5097 [9:53:01<38:42,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4785.json (38288 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  94%|█████████▍| 4791/5097 [9:53:38<38:40,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4790.json (38328 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  94%|█████████▍| 4796/5097 [9:54:15<37:08,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4795.json (38368 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  94%|█████████▍| 4801/5097 [9:54:52<37:07,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4800.json (38408 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  94%|█████████▍| 4806/5097 [9:55:29<36:21,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4805.json (38448 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  94%|█████████▍| 4811/5097 [9:56:06<35:38,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4810.json (38488 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  94%|█████████▍| 4816/5097 [9:56:44<34:54,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4815.json (38528 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  95%|█████████▍| 4821/5097 [9:57:21<34:17,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4820.json (38568 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  95%|█████████▍| 4826/5097 [9:57:58<33:29,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4825.json (38608 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  95%|█████████▍| 4831/5097 [9:58:34<32:47,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4830.json (38648 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  95%|█████████▍| 4836/5097 [9:59:12<32:22,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4835.json (38688 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  95%|█████████▍| 4841/5097 [9:59:48<31:22,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4840.json (38728 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  95%|█████████▌| 4846/5097 [10:00:25<31:05,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4845.json (38768 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  95%|█████████▌| 4851/5097 [10:01:02<30:21,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4850.json (38808 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  95%|█████████▌| 4856/5097 [10:01:40<29:52,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4855.json (38848 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  95%|█████████▌| 4861/5097 [10:02:17<29:09,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4860.json (38888 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  95%|█████████▌| 4866/5097 [10:02:54<28:13,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4865.json (38928 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  96%|█████████▌| 4871/5097 [10:03:31<27:49,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4870.json (38968 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  96%|█████████▌| 4876/5097 [10:04:06<26:46,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4875.json (39008 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  96%|█████████▌| 4881/5097 [10:04:45<26:52,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4880.json (39048 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  96%|█████████▌| 4886/5097 [10:05:23<26:53,  7.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4885.json (39088 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  96%|█████████▌| 4891/5097 [10:06:00<25:03,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4890.json (39128 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  96%|█████████▌| 4896/5097 [10:06:35<23:59,  7.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4895.json (39168 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  96%|█████████▌| 4901/5097 [10:07:11<23:16,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4900.json (39208 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  96%|█████████▋| 4906/5097 [10:07:48<23:22,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4905.json (39248 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  96%|█████████▋| 4911/5097 [10:08:25<22:39,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4910.json (39288 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  96%|█████████▋| 4916/5097 [10:09:02<22:18,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4915.json (39328 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  97%|█████████▋| 4921/5097 [10:09:39<21:31,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4920.json (39368 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  97%|█████████▋| 4926/5097 [10:10:17<20:58,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4925.json (39408 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  97%|█████████▋| 4931/5097 [10:10:54<20:38,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4930.json (39448 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  97%|█████████▋| 4936/5097 [10:11:31<20:29,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4935.json (39488 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  97%|█████████▋| 4941/5097 [10:12:09<19:33,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4940.json (39528 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  97%|█████████▋| 4946/5097 [10:12:46<19:01,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4945.json (39568 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  97%|█████████▋| 4951/5097 [10:13:25<18:29,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4950.json (39608 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  97%|█████████▋| 4956/5097 [10:14:01<17:14,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4955.json (39648 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  97%|█████████▋| 4961/5097 [10:14:39<17:05,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4960.json (39688 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  97%|█████████▋| 4966/5097 [10:15:16<16:22,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4965.json (39728 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  98%|█████████▊| 4971/5097 [10:15:53<15:29,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4970.json (39768 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  98%|█████████▊| 4976/5097 [10:16:30<15:01,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4975.json (39808 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  98%|█████████▊| 4981/5097 [10:17:07<14:00,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4980.json (39848 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  98%|█████████▊| 4986/5097 [10:17:45<14:05,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4985.json (39888 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  98%|█████████▊| 4991/5097 [10:18:22<13:18,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4990.json (39928 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  98%|█████████▊| 4996/5097 [10:18:58<12:21,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_4995.json (39968 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  98%|█████████▊| 5001/5097 [10:19:35<11:45,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_5000.json (40008 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  98%|█████████▊| 5006/5097 [10:20:12<11:22,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_5005.json (40048 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  98%|█████████▊| 5011/5097 [10:20:50<10:50,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_5010.json (40088 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  98%|█████████▊| 5016/5097 [10:21:27<10:03,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_5015.json (40128 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  99%|█████████▊| 5021/5097 [10:22:04<09:19,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_5020.json (40168 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  99%|█████████▊| 5026/5097 [10:22:42<08:53,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_5025.json (40208 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  99%|█████████▊| 5031/5097 [10:23:19<08:15,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_5030.json (40248 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  99%|█████████▉| 5036/5097 [10:23:56<07:26,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_5035.json (40288 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  99%|█████████▉| 5041/5097 [10:24:33<06:54,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_5040.json (40328 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  99%|█████████▉| 5046/5097 [10:25:10<06:24,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_5045.json (40368 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  99%|█████████▉| 5051/5097 [10:25:47<05:44,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_5050.json (40408 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  99%|█████████▉| 5056/5097 [10:26:24<05:00,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_5055.json (40448 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  99%|█████████▉| 5061/5097 [10:27:01<04:26,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_5060.json (40488 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  99%|█████████▉| 5066/5097 [10:27:38<03:51,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_5065.json (40528 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  99%|█████████▉| 5071/5097 [10:28:15<03:17,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_5070.json (40568 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|█████████▉| 5076/5097 [10:28:52<02:34,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_5075.json (40608 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|█████████▉| 5081/5097 [10:29:29<01:59,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_5080.json (40648 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|█████████▉| 5086/5097 [10:30:06<01:21,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_5085.json (40688 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|█████████▉| 5091/5097 [10:30:43<00:43,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_5090.json (40728 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|█████████▉| 5096/5097 [10:31:19<00:07,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved intermediate results to llama3_llava_next_8b_coco_results_test_temp_batch_5095.json (40768 captions so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5097/5097 [10:31:26<00:00,  7.43s/it]\n"
     ]
    }
   ],
   "source": [
    "# Full inference on test set with efficient batch processing\n",
    "results = []\n",
    "total_batches = (len(image_files) + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "\n",
    "for batch_idx in tqdm(range(total_batches), desc=\"Processing batches\"):\n",
    "    start_idx = batch_idx * BATCH_SIZE\n",
    "    end_idx = min((batch_idx + 1) * BATCH_SIZE, len(image_files))\n",
    "    \n",
    "    batch_files = image_files[start_idx:end_idx]\n",
    "    image_paths_batch = []\n",
    "    image_ids_batch = []\n",
    "    \n",
    "    # Prepare batch data\n",
    "    for filename in batch_files:\n",
    "        image_path = os.path.join(IMAGE_DIR, filename)\n",
    "        try:\n",
    "            if not os.path.exists(image_path):\n",
    "                print(f\"Warning: File not found: {image_path}\")\n",
    "                continue\n",
    "            \n",
    "            img_id = extract_image_id(filename)\n",
    "            image_paths_batch.append(image_path)\n",
    "            image_ids_batch.append(img_id)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error preparing {filename}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if not image_paths_batch:\n",
    "        print(f\"Warning: Empty batch at index {batch_idx}\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Process batch efficiently\n",
    "        captions = process_batch_efficient(image_paths_batch, model, processor, DEVICE)\n",
    "        \n",
    "        # Append to results\n",
    "        for img_id, caption in zip(image_ids_batch, captions):\n",
    "            results.append({\n",
    "                \"image_id\": img_id,\n",
    "                \"caption\": caption\n",
    "            })\n",
    "            \n",
    "        # Save intermediate results every 5 batches for safety\n",
    "        if batch_idx > 0 and batch_idx % 5 == 0:\n",
    "            temp_file = OUTPUT_FILE.replace('.json', f'_temp_batch_{batch_idx}.json')\n",
    "            with open(temp_file, 'w') as f:\n",
    "                json.dump(results, f, indent=2)\n",
    "            print(f\"  ✓ Saved intermediate results to {temp_file} ({len(results)} captions so far)\")\n",
    "        \n",
    "        # Clear memory after each batch\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch {batch_idx}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cd873a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving final results to llama3_llava_next_8b_coco_results_test.json\n",
      "✓ Final results saved successfully. Total predictions: 40775\n",
      "\n",
      "Summary:\n",
      "  Total images processed: 40775\n",
      "  Total images in directory: 40775\n",
      "  Success rate: 100.0%\n",
      "  Average caption length: 55.9 characters\n",
      "  Valid captions: 40775\n",
      "\n",
      "Sample predictions:\n",
      "  1. Image ID: 1\n",
      "     Caption: A taxi cab parked next to a black iron fence.\n",
      "  2. Image ID: 14\n",
      "     Caption: A man riding a skateboard down a street next to a man on a motorcycle.\n",
      "  3. Image ID: 16\n",
      "     Caption: A baseball player swinging a bat at a ball.\n",
      "  4. Image ID: 27\n",
      "     Caption: A dog sitting in the passenger seat of a car with a bicycle on top.\n",
      "  5. Image ID: 57\n",
      "     Caption: A man in a red shirt and shorts playing tennis on a clay court.\n",
      "\n",
      "Processing complete!\n"
     ]
    }
   ],
   "source": [
    "# Save final results\n",
    "print(f\"\\nSaving final results to {OUTPUT_FILE}\")\n",
    "with open(OUTPUT_FILE, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print(f\"✓ Final results saved successfully. Total predictions: {len(results)}\")\n",
    "\n",
    "# Print summary statistics\n",
    "if results:\n",
    "    print(\"\\nSummary:\")\n",
    "    print(f\"  Total images processed: {len(results)}\")\n",
    "    print(f\"  Total images in directory: {len(image_files)}\")\n",
    "    print(f\"  Success rate: {len(results)/len(image_files)*100:.1f}%\")\n",
    "    \n",
    "    # Calculate average caption length (excluding error messages)\n",
    "    valid_captions = [r['caption'] for r in results if \"Error generating caption\" not in r['caption'] and \"No caption generated\" not in r['caption']]\n",
    "    if valid_captions:\n",
    "        avg_length = sum(len(caption) for caption in valid_captions) / len(valid_captions)\n",
    "        print(f\"  Average caption length: {avg_length:.1f} characters\")\n",
    "        print(f\"  Valid captions: {len(valid_captions)}\")\n",
    "    \n",
    "    # Show some sample results\n",
    "    print(\"\\nSample predictions:\")\n",
    "    for i, result in enumerate(results[:5]):\n",
    "        print(f\"  {i+1}. Image ID: {result['image_id']}\")\n",
    "        print(f\"     Caption: {result['caption']}\")\n",
    "else:\n",
    "    print(\"Warning: No results were generated. Check for errors above.\")\n",
    "\n",
    "print(\"\\nProcessing complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
